---
description: 
globs: 
alwaysApply: false
---
# Rule: Generating Sub-Tasks from Tasks Analysis

## 🧠 Enhanced Analysis Tools - USE THESE!

**CRITICAL:** Leverage these tools throughout the sub-task generation process:

### 🧩 Memory MCP Integration
- **Retrieve context:** `memory_search` for PRD, TRD, and task decisions to maintain consistency
- **Store implementation patterns:** `memory_store_chunk` with successful sub-task structures and patterns
- **Reference similar breakdowns:** `memory_search` for comparable sub-task implementations from past projects
- **Track development workflow:** `memory_tasks` for sub-task generation and implementation progress
- **Store decisions:** `memory_store_decision` for sub-task boundary decisions and implementation approaches
- **Tags to use:** `["sub-tasks", "implementation", "breakdown", "feature-name", "development"]`

### 🔄 Sequential Thinking MCP
- **Use for:** Complex task decomposition, dependency analysis, implementation sequencing
- **Pattern:** Task requirements → technical components → implementation steps → sub-task boundaries
- **Benefit:** Ensures sub-tasks are logically sequenced and properly sized for LLM implementation
- **When:** During task breakdown analysis, dependency mapping, and implementation planning

**IMPLEMENTATION TIP:** Each sub-task should include Memory MCP actions to store implementation progress and learnings!

**Pro tip:** Store every implementation decision and pattern to build a knowledge base of successful development approaches!

## Goal

To guide an AI assistant in analyzing tasks and breaking them down into detailed, implementable sub-tasks. Each sub-task must be specific, actionable, and small enough to be completed in a single development session while contributing to the completion of its parent task.

## Process

1. **Read Tasks Document:** The AI must first read the tasks-[feature-name].md document to understand the atomic phases from `/docs/pre-development/tasks/`
   - 🧩 **Memory Action:** `memory_search` to retrieve all related context from PRD, TRD, and validation steps

2. **Verify Chain Validation:** Ensure validation-report-[feature-name].md shows PASS status and tasks are validated
   - 🧩 **Memory Action:** `memory_search` for validation patterns and any documented risks

3. **Analyze Task Structure:** Extract and understand each task's scope, dependencies, and deliverables
   - 🔄 **Sequential Thinking:** Map task boundaries to implementation components and dependencies

4. **Apply Granular Breakdown:** Ensure each sub-task is specific and implementable
   - 🔄 **Sequential Thinking:** Validate each sub-task is atomic and can be completed in 2-4 hours

5. **Generate Sub-Tasks:** Create detailed sub-task specifications using the structure below
   - 🧩 **Memory Action:** `memory_store_decision` for sub-task breakdown rationale and implementation approach
6. **Optional User Review:** Since sub-tasks are implementation details, user review is optional:
   - "I've created detailed sub-tasks for implementation. Would you like to review the granularity, or shall I proceed with saving them?"
   - If user wants to review, WAIT for feedback
   - If user approves or skips review, proceed to save
   - 🧩 **Memory Action:** `memory_store_chunk` with user feedback on sub-task granularity (if provided)

7. **Save Output:** Create individual files for each task and sub-task in `/docs/pre-development/tasks/` directory (see File Organization section)
   - 🧩 **Memory Action:** `memory_create_thread` completing the full development chain: PRD → TRD → Tasks → Sub-tasks

## Input Document Analysis

### Tasks Analysis Requirements
- **Task Overview:** Extract the deliverable and atomic validation from each task
- **Functional Scope:** Understand what features are included in each task
- **Technical Scope:** Identify the technical components and architecture elements
- **Dependencies:** Map prerequisite tasks and blocking relationships
- **Acceptance Criteria:** Use acceptance criteria to guide sub-task creation

### Technical Context Requirements
- **PRD Reference:** Cross-reference with original PRD for detailed requirements
- **TRD Reference:** Leverage technical specifications for implementation details
- **Architecture Patterns:** Ensure sub-tasks align with defined architecture
- **Testing Strategy:** Include testing sub-tasks based on overall testing approach
- **Quality Standards:** Incorporate code quality and review requirements

## Sub-Task Principles

### Definition of "Implementable Sub-Task"
Each sub-task MUST be:
- **Single Session:** Can be completed in 2-4 hours maximum
- **Specific:** Has clear, unambiguous requirements
- **Testable:** Can be validated independently
- **Incremental:** Builds toward task completion
- **Technical:** Includes specific implementation details

### Sub-Task Validation Checklist
Before finalizing each sub-task, ensure:
- [ ] **Clear Deliverable:** Specific code, config, or documentation output
- [ ] **Implementation Path:** Obvious how to implement the requirement
- [ ] **Test Strategy:** Clear how to validate the sub-task
- [ ] **Integration Point:** Clear how it fits with other sub-tasks
- [ ] **Definition of Done:** Unambiguous completion criteria

## Sub-Task Structure

Each generated sub-task should include these sections (strictly follow this structure):

### 1. Sub-Task Overview
- **Sub-Task ID:** ST-T-[task-id]-[number] (e.g., ST-T-001-001, ST-T-001-002)
- **Sub-Task Name:** Clear, action-oriented name (e.g., "Create Task Entity with Validation")
- **Parent Task:** Reference to task (e.g., "T-001: CLI Foundation with Local Storage")
- **Estimated Duration:** 2-4 hours maximum
- **Implementation Type:** Code, Configuration, Testing, Documentation, Research

### 🔀 Git Workflow (REQUIRED)
**BEFORE STARTING:**
```bash
git checkout -b feature/ST-T-[task-id]-[num]-[short-desc]
# Example: git checkout -b feature/ST-T-001-001-task-entity
```

**AFTER COMPLETING:**
```bash
git add .
git commit -m "feat(ST-T-[task-id]-[num]): [brief description]

Implemented:
- [what was built]

Deviations:
- [any changes from plan]

Notes:
- [implementation details]"

git push -u origin feature/ST-T-[task-id]-[num]-[short-desc]
```

### 2. Deliverable Specification
- **Primary Output:** Specific files, functions, or components to create
- **Code Location:** Exact file paths and directory structure
- **File Size Guidelines:** 
  - **Target:** <300 lines per file for optimal LLM processing
  - **Maximum:** 500 lines per file (hard limit)
  - **Split Strategy:** If approaching 500 lines, break into logical modules
- **Technical Requirements:** Specific technologies, libraries, patterns to use
- **Interface Definition:** APIs, function signatures, data structures
- **Architecture Compliance:** Hexagonal Architecture pattern requirements
- **lib-commons Usage:** Required lib-commons components and utilities
- **lib-auth Integration:** Authentication/authorization requirements (for Midaz projects)

### 3. Implementation Details
- **Step-by-Step Approach:** Numbered implementation steps
- **Code Examples:** Key code snippets or structure examples
- **Configuration Changes:** Specific config files or environment changes
- **Dependencies:** Libraries, packages, or tools needed

### 4. Acceptance Criteria
- **Functional Criteria:** What the code must do
- **Technical Criteria:** Code quality, performance, security requirements
- **Integration Criteria:** How it connects with existing components
- **Test Criteria:** Specific tests that must pass

### 5. Testing Requirements
- **Unit Tests:** Specific test cases to write
- **Integration Tests:** Integration points to test
- **Manual Testing:** Manual validation steps
- **Test Data:** Required test fixtures or data

### 6. Definition of Done
- **Code Complete:** All code written and reviewed
- **Tests Passing:** All tests written and passing
- **Documentation Updated:** Relevant docs updated
- **Integration Verified:** Works with existing components
- **Quality Checks Pass:** All language-specific quality validation complete
- **Git Workflow Complete:** Branch created, committed with implementation details and deviations
- **PR Submitted:** Pull request created against tasks-implementation branch
- **Review Approved:** Code review completed and PR merged
- **🧩 Memory Actions Complete:** Implementation progress and learnings stored in memory

### 7. Quality Assurance Requirements
**CRITICAL:** Each sub-task MUST include programming language-specific quality checks:

#### Go Projects
```bash
# Run after each sub-task completion
make fmt              # Code formatting
make vet              # Static analysis
gosec ./...          # Security analysis
govulncheck ./...    # Vulnerability check
go test ./...        # Test execution
```

#### TypeScript/JavaScript Projects
```bash
# Run after each sub-task completion
npm run lint         # ESLint code quality
npm run typecheck    # TypeScript validation
npm test            # Test execution
npm run build       # Production build verification
```

#### Python Projects
```bash
# Run after each sub-task completion
ruff check .         # Linting and formatting
mypy .              # Type checking
pytest              # Test execution
black .             # Code formatting
```

#### Other Languages
- **Rust:** `cargo fmt && cargo clippy && cargo test`
- **Java:** `mvn compile && mvn test && mvn checkstyle:check`
- **C#:** `dotnet format && dotnet test && dotnet build`

**FAILURE PROTOCOL:** If quality checks fail:
1. Fix issues immediately before proceeding
2. Document quality violations in memory: `memory_store_chunk` with tag `quality-violation`
3. Re-run checks to ensure resolution
4. Only mark sub-task as complete when ALL quality checks pass

### 🚨 Pre-Emptive Quality Guidance (CRITICAL)

**IMPORTANT:** Use these patterns to avoid common quality check failures from the start:

#### Go Language Anti-Patterns to Avoid
**Error Handling:**
```go
// ❌ WRONG - causes errcheck/staticcheck violations
fmt.Errorf("user not found")  // For static messages

// ✅ CORRECT - use errors.New for static messages
errors.New("user not found")

// ✅ CORRECT - use fmt.Errorf only with variables
fmt.Errorf("user %s not found", userID)
```

**String Operations:**
```go
// ❌ WRONG - causes perfsprint violations
fmt.Sprintf("%d", number)     // Use strconv.Itoa(number)
fmt.Sprintf("%s", variable)   // Use string(variable) or direct concatenation
fmt.Sprintf("prefix%s", var)  // Use "prefix"+var

// ✅ CORRECT - performance optimized
strconv.Itoa(number)          // For integer to string
"prefix" + variable           // For simple concatenation
```

**Function Complexity (Prevent gocyclo/nestif violations):**
```go
// ❌ WRONG - high complexity, deep nesting
func ProcessSubTask(data SubTaskData) error {
    if data.Valid {
        if data.Type == "implementation" {
            if data.Dependencies != nil {
                if len(data.Dependencies) > 0 {
                    // Deep nesting causes nestif violations
                }
            }
        }
    }
    return nil
}

// ✅ CORRECT - early returns, guard clauses
func ProcessSubTask(data SubTaskData) error {
    if !data.Valid {
        return errors.New("invalid sub-task data")
    }
    if data.Type != "implementation" {
        return nil  // Early return reduces complexity
    }
    if data.Dependencies == nil || len(data.Dependencies) == 0 {
        return nil  // Guard clause prevents nesting
    }
    
    // Main logic here - minimal nesting
    return data.Process()
}
```

**Preallocation and Efficiency:**
```go
// ❌ WRONG - causes prealloc violations
var results []SubTaskResult
for _, task := range subTasks {
    results = append(results, processSubTask(task))
}

// ✅ CORRECT - pre-allocate slices
results := make([]SubTaskResult, 0, len(subTasks))
for _, task := range subTasks {
    results = append(results, processSubTask(task))
}
```

**Context Usage in Sub-Tasks:**
```go
// ❌ WRONG - causes unparam violations
func ExecuteSubTask(ctx context.Context, task SubTask, metadata string) error {
    // ctx and metadata never used - unparam violations
    return task.Run()
}

// ✅ CORRECT - use all parameters or remove them
func ExecuteSubTask(task SubTask) error {
    return task.Run()
}

// ✅ OR use context properly for cancellation
func ExecuteSubTask(ctx context.Context, task SubTask) error {
    select {
    case <-ctx.Done():
        return ctx.Err()
    default:
        return task.RunWithContext(ctx)
    }
}
```

#### TypeScript/JavaScript Sub-Task Patterns
```typescript
// ❌ WRONG - common sub-task implementation issues
const processSubTask = (data: any) => {              // Avoid 'any'
    let result = data.process();                     // Use const when possible
    if (result == null) return null;                 // Use === for strict equality
}

// ✅ CORRECT - type-safe sub-task implementation
const processSubTask = (data: SubTaskData): SubTaskResult | null => {
    const result = data.process();                   // const for immutable
    if (result === null) return null;                // Strict equality
    return result;
}
```

#### Python Sub-Task Patterns
```python
# ❌ WRONG - common sub-task violations
def execute_sub_task(data):                         # Missing type hints
    if hasattr(data, 'process'):                    # Unsafe attribute check
        return data.process()

# ✅ CORRECT - type-safe sub-task patterns
from typing import Protocol, Optional

class SubTaskData(Protocol):
    def process(self) -> Optional[str]: ...

def execute_sub_task(data: SubTaskData) -> Optional[str]:
    return data.process()
```

### 🎯 Sub-Task Specific Quality Strategies

**Keep Sub-Task Functions Focused:**
- **Target:** <15 lines per sub-task function
- **Maximum:** 30 lines (split if larger)
- **Strategy:** One responsibility per sub-task function

**Sub-Task Error Handling:**
```go
// ✅ RECOMMENDED pattern for sub-task error handling
func ExecuteSubTaskWithValidation(input SubTaskInput) (*SubTaskResult, error) {
    // Validate sub-task prerequisites
    if err := input.ValidatePrerequisites(); err != nil {
        return nil, fmt.Errorf("sub-task prerequisites not met: %w", err)
    }
    
    // Execute sub-task with proper error wrapping
    result, err := input.Execute()
    if err != nil {
        return nil, fmt.Errorf("sub-task execution failed: %w", err)
    }
    
    // Validate sub-task output
    if err := result.Validate(); err != nil {
        return nil, fmt.Errorf("sub-task output validation failed: %w", err)
    }
    
    return result, nil
}
```

**Avoid Common Sub-Task Anti-Patterns:**
```go
// ❌ WRONG - common sub-task implementation issues
func ProcessMultipleSubTasks(tasks []SubTask) error {
    for i := 0; i < len(tasks); i++ {               // Use range instead
        if tasks[i].Type == "critical" {
            if tasks[i].Dependencies != nil {
                if len(tasks[i].Dependencies) > 0 {  // Nested conditions
                    // Complex nested logic
                }
            }
        }
    }
    return nil
}

// ✅ CORRECT - clean sub-task processing
func ProcessMultipleSubTasks(tasks []SubTask) error {
    for _, task := range tasks {                    // Use range for cleaner iteration
        if err := processIndividualSubTask(task); err != nil {
            return fmt.Errorf("sub-task %s failed: %w", task.ID, err)
        }
    }
    return nil
}

func processIndividualSubTask(task SubTask) error {
    if task.Type != "critical" {
        return nil  // Early return for non-critical tasks
    }
    if task.Dependencies == nil || len(task.Dependencies) == 0 {
        return nil  // Guard clause prevents nesting
    }
    
    // Process critical task with dependencies
    return task.ProcessWithDependencies()
}
```

### 📏 Sub-Task File Size Guidelines

**Optimal Sub-Task File Sizes:**
- **Go sub-task files:** <200 lines target, 300 lines maximum
- **TypeScript sub-task files:** <150 lines target, 250 lines maximum
- **Python sub-task files:** <120 lines target, 200 lines maximum

**Sub-Task Decomposition Strategy:**
1. **Split by responsibility** - Each file handles one sub-task type
2. **Extract common utilities** - Shared logic goes to utility files
3. **Separate concerns** - Data processing, validation, and I/O in different files
4. **Use interfaces** - Define clear contracts between sub-task components

### 🔍 Sub-Task Pre-Implementation Quality Checklist

Before implementing any sub-task, ensure specification includes:
- [ ] **Single responsibility** - Each sub-task does one thing well
- [ ] **Clear input/output** - Well-defined interfaces and data structures
- [ ] **Error handling strategy** - Proper error propagation and context
- [ ] **Dependency management** - Clear prerequisite handling
- [ ] **Testing strategy** - Unit tests for each sub-task function
- [ ] **Performance considerations** - Efficient algorithms and data structures
- [ ] **Memory management** - Proper resource cleanup and lifecycle
- [ ] **Type safety** - Strong typing throughout sub-task implementation

### 🔄 Quality-First Sub-Task Implementation Flow

**For each sub-task implementation:**
1. **Design interfaces first** - Define clear input/output contracts
2. **Write tests before code** - TDD approach for better quality
3. **Implement with quality patterns** - Use proven patterns from the start
4. **Run quality checks frequently** - Check early and often
5. **Refactor immediately** - Fix quality issues as soon as they appear

**Sub-Task Implementation Template:**
```go
// ✅ RECOMMENDED sub-task implementation template
package subtask

import (
    "context"
    "errors"
    "fmt"
)

// SubTaskInput defines the input contract for this sub-task
type SubTaskInput struct {
    ID           string            `json:"id" validate:"required"`
    Data         map[string]any    `json:"data" validate:"required"`
    Dependencies []string          `json:"dependencies"`
}

// SubTaskResult defines the output contract for this sub-task
type SubTaskResult struct {
    ID      string         `json:"id"`
    Status  string         `json:"status"`
    Output  map[string]any `json:"output"`
    Errors  []string       `json:"errors,omitempty"`
}

// Execute implements the sub-task with proper error handling
func (input *SubTaskInput) Execute(ctx context.Context) (*SubTaskResult, error) {
    // Early validation
    if err := input.Validate(); err != nil {
        return nil, fmt.Errorf("input validation failed: %w", err)
    }
    
    // Check context cancellation
    select {
    case <-ctx.Done():
        return nil, ctx.Err()
    default:
    }
    
    // Main sub-task logic
    result := &SubTaskResult{
        ID:     input.ID,
        Status: "processing",
        Output: make(map[string]any),
    }
    
    if err := input.processData(result); err != nil {
        return nil, fmt.Errorf("data processing failed: %w", err)
    }
    
    result.Status = "completed"
    return result, nil
}

// Validate ensures input meets requirements
func (input *SubTaskInput) Validate() error {
    if input.ID == "" {
        return errors.New("sub-task ID is required")
    }
    if input.Data == nil {
        return errors.New("sub-task data is required")
    }
    return nil
}

// processData handles the core sub-task logic
func (input *SubTaskInput) processData(result *SubTaskResult) error {
    // Implementation specific to this sub-task
    // Keep this function focused and small
    return nil
}
```

### 🧠 Required Memory Actions During Implementation
**CRITICAL:** Every sub-task implementation MUST include these Memory MCP actions:

### 🔄 Sequential Thinking for Complex Sub-Tasks
**RECOMMENDED:** For complex implementation decisions, use Sequential Thinking MCP:
```
mcp__sequential-thinking__sequentialthinking
  thought="[current implementation challenge or decision point]"
  thought_number=1
  total_thoughts=3-5
  next_thought_needed=true
```
Use this when facing:
- Architecture decisions within the sub-task
- Complex algorithm implementations  
- Integration challenges
- Performance optimization choices

**Before Starting:**
```
memory_store_chunk
  content="Starting ST-[ID]: [task-name]. Context: [brief context]"
  tags=["sub-task", "started", "ST-[ID]", "feature-name"]
  session_id="[current-session]"
  repository="[project-repo]"
```

**During Implementation:**
```
memory_store_decision 
  decision="[key implementation choice made]"
  rationale="[why this approach was chosen]"
  alternatives="[other options considered]"
  session_id="[current-session]"
  repository="[project-repo]"
```

**After Completion:**
```
memory_store_chunk
  content="Completed ST-[ID]: [summary]. Deviations: [any changes]. Learnings: [insights gained]"
  tags=["sub-task", "completed", "ST-[ID]", "learnings"]
  session_id="[current-session]"
  repository="[project-repo]"
```

### 7. Dependencies and Blockers
- **Required Sub-Tasks:** Sub-tasks that must be completed first
- **External Dependencies:** Third-party services, libraries, or tools

## User Interaction Guidelines

### Optional Review Process
Since sub-tasks are implementation details, user review is optional but available:

1. **Summary Presentation:** Show task breakdown summary first
2. **Granularity Check:** Ask if level of detail is appropriate
3. **Quick Approval:** Allow user to skip detailed review

### Example Interaction Flow
```
AI: "I've broken down the main tasks into detailed sub-tasks:

**MT-001: Foundation Phase** → 8 sub-tasks
- ST-001: Project setup and configuration (2h)
- ST-002: Database schema creation (3h)
- ST-003: Basic authentication implementation (4h)
- ... (5 more sub-tasks)

**MT-002: Core Features** → 12 sub-tasks
**MT-003: Enhancements** → 6 sub-tasks

Total: 26 implementation sub-tasks

Would you like to:
1. Review the detailed breakdown
2. Adjust the granularity (more/fewer sub-tasks)
3. Proceed with saving these sub-tasks

What's your preference?"

[WAIT FOR USER RESPONSE - OR PROCEED IF USER SAYS "PROCEED"]

User: "Proceed with saving"

AI: "Great! I'll save all sub-tasks in the organized structure..."
```
- **Environmental Requirements:** Development environment setup needs
- **Potential Blockers:** Known issues or complications

### 8. Integration Notes
- **Component Interfaces:** How this integrates with other components
- **Data Flow:** How data moves through this component
- **Error Handling:** How errors are managed and propagated
- **Configuration Impact:** Environment or config changes needed
- **Architecture Pattern Adherence:** Specific Hexagonal Architecture requirements
- **lib-commons Integration Points:** How lib-commons utilities are leveraged
- **lib-auth Integration Points:** Authentication/authorization integration (for Midaz projects)

## Git Workflow Requirements

### For Each Sub-Task Implementation:

1. **Branch Creation:** At the start of each sub-task
   ```bash
   git checkout -b feature/ST-T-[task-id]-[num]-[short-description]
   # Example: git checkout -b feature/ST-T-001-001-task-entity
   ```

2. **Implementation:** Follow the sub-task specification

3. **Commit Requirements:** At the end of each sub-task
   ```bash
   git add .
   git commit -m "feat(ST-T-[task-id]-[num]): [implementation summary]
   
   Implemented: [what was built]
   Deviations: [any changes from original plan]
   Notes: [important implementation details]"
   ```

4. **Pull Request:** Submit PR against tasks-implementation branch
   ```bash
   git push origin feature/ST-T-[task-id]-[num]-[short-description]
   # Create PR: feature/ST-T-[task-id]-[num] → tasks-implementation
   ```

## Example Sub-Task Format

```markdown
## ST-T-001-001: Create Task Entity with Validation

### 1. Sub-Task Overview
- **Sub-Task ID:** ST-T-001-001
- **Sub-Task Name:** Create Task Entity with Validation
- **Parent Task:** T-001: CLI Foundation with Local Storage
- **Estimated Duration:** 3 hours
- **Implementation Type:** Code

### 2. Deliverable Specification
- **Primary Output:** Task entity struct with validation methods
- **Code Location:** `cli/internal/domain/entities/task.go`
- **Technical Requirements:** Go structs with validation tags, error handling
- **Interface Definition:** Task struct with Create, Update, Validate methods

### 3. Implementation Details
- **Step-by-Step Approach:**
  1. Create `cli/internal/domain/entities/` directory
  2. Define Task struct with all required fields
  3. Add validation tags using go-playground/validator
  4. Implement validation methods
  5. Add custom validation for business rules
  6. Create constructor function with validation
  7. Add error handling for validation failures

- **Code Examples:**
  ```go
  type Task struct {
      ID          string    `json:"id" validate:"required,uuid"`
      Content     string    `json:"content" validate:"required,min=1,max=1000"`
      Status      Status    `json:"status" validate:"required,oneof=pending in_progress completed cancelled"`
      Priority    Priority  `json:"priority" validate:"required,oneof=low medium high"`
      Repository  string    `json:"repository" validate:"required"`
      CreatedAt   time.Time `json:"created_at"`
      UpdatedAt   time.Time `json:"updated_at"`
  }
  
  func NewTask(content, repository string) (*Task, error) {
      // Implementation with validation
  }
  ```

- **Configuration Changes:** None required
- **Dependencies:** 
  - `github.com/go-playground/validator/v10`
  - `github.com/google/uuid`

### 4. Acceptance Criteria
- **Functional Criteria:**
  - Task struct contains all required fields from PRD
  - Validation prevents invalid tasks from being created
  - Constructor function enforces business rules
  
- **Technical Criteria:**
  - Code follows Go conventions and project style
  - All public methods have documentation
  - Error messages are user-friendly
  
- **Integration Criteria:**
  - Can be imported by other domain services
  - JSON serialization works correctly
  
- **Test Criteria:**
  - All validation scenarios covered by tests
  - Constructor edge cases tested

### 5. Testing Requirements
- **Unit Tests:**
  - Valid task creation succeeds
  - Invalid content (empty, too long) fails validation
  - Invalid status/priority values fail validation
  - Invalid repository format fails validation
  - Constructor generates correct timestamps

- **Integration Tests:** None required (domain entity)
- **Manual Testing:** Verify JSON serialization in CLI output
- **Test Data:** Create test fixtures for valid/invalid task data

### 6. Definition of Done
- **Code Complete:** Task entity fully implemented with validation
- **Tests Passing:** All unit tests written and passing (≥90% coverage)
- **Documentation Updated:** Godoc comments on all public methods
- **Integration Verified:** Can be used by TaskService
- **Review Approved:** Code review completed by team lead

### 7. Dependencies and Blockers
- **Required Sub-Tasks:** None (foundational task)
- **External Dependencies:** Go validation library
- **Environmental Requirements:** Go 1.23+ development environment
- **Potential Blockers:** Validation library compatibility issues

### 8. Integration Notes
- **Component Interfaces:** Used by TaskService in domain layer
- **Data Flow:** Created from CLI input, stored via Storage interface
- **Error Handling:** Returns structured validation errors
- **Configuration Impact:** None
```

## Quality Standards

### Granularity Validation
Each sub-task must:
- [ ] **Single Purpose:** Addresses one specific implementation concern
- [ ] **Time-Bounded:** Can be completed in one development session
- [ ] **Clear Output:** Produces identifiable deliverable
- [ ] **Testable Scope:** Can be validated independently
- [ ] **Integration Ready:** Fits cleanly with other sub-tasks

### Implementation Readiness
Verify each sub-task:
- [ ] **Technical Clarity:** No ambiguity about what to implement
- [ ] **Architecture Alignment:** Follows established patterns
- [ ] **Dependency Management:** Clear prerequisite relationships
- [ ] **Test Coverage:** Testing approach clearly defined
- [ ] **Error Handling:** Error scenarios considered

## Output Structure

### File Organization

**IMPORTANT: Each task and sub-task must be saved in separate files for simplified management.**

```
docs/pre-development/tasks/
├── tasks-[feature-name].md                        # Input document (overview)
├── T-[id]/                                         # Directory per task
│   ├── task.md                                    # Task specification
│   ├── ST-T-[id]-[num].md                         # Individual sub-task files
│   ├── ST-T-[id]-[num].md
│   └── ...
├── task-dependencies.md                            # Cross-task dependency mapping
├── implementation-checklist.md                     # Overall progress tracking
└── task-index.md                                  # Index of all tasks and sub-tasks
```

**File Naming Convention:**
- Tasks: `docs/pre-development/tasks/T-[id]/task.md` (e.g., `T-001/task.md`)
- Sub-Tasks: `docs/pre-development/tasks/T-[id]/ST-T-[id]-[num].md` (e.g., `T-001/ST-T-001-001.md`)
- Dependencies: `docs/pre-development/tasks/task-dependencies.md`
- Index: `docs/pre-development/tasks/task-index.md`

**Benefits of Individual Files:**
- **Simplified Management:** Each task can be tracked, assigned, and updated independently
- **Version Control:** Clean git history with granular changes per task
- **Parallel Development:** Multiple developers can work on different sub-tasks simultaneously
- **Progress Tracking:** Individual file status reflects completion state
- **Code Review:** Focused reviews per sub-task rather than large documents

### Task Index File Structure

Create `docs/pre-development/tasks/task-index.md` to maintain an overview of all tasks:

```markdown
# Task Index - [Feature Name]

## Tasks Overview

| Task ID | Status | Name | Sub-Tasks | Estimated Total |
|---------|--------|------|-----------|-----------------|
| T-001 | In Progress | CLI Foundation | 5 | 16 hours |
| T-002 | Pending | PRD Processing | 6 | 20 hours |
| T-003 | Pending | Server Integration | 4 | 14 hours |

## Sub-Tasks by Task

### T-001: CLI Foundation
- [x] [ST-T-001-001](mdc:T-001/ST-T-001-001.md): Task Entity (3h) - ✅ Complete
- [ ] [ST-T-001-002](mdc:T-001/ST-T-001-002.md): Task Service (4h) - 🔄 In Progress
- [ ] [ST-T-001-003](mdc:T-001/ST-T-001-003.md): Local Storage (3h) - ⏳ Pending
- [ ] [ST-T-001-004](mdc:T-001/ST-T-001-004.md): CLI Commands (4h) - ⏳ Pending
- [ ] [ST-T-001-005](mdc:T-001/ST-T-001-005.md): Integration Tests (2h) - ⏳ Pending

**Progress:** 1/5 Complete (20%)
```

**Status Icons:**
- ✅ Complete
- 🔄 In Progress
- ⏳ Pending
- ❌ Blocked
- 🚫 Cancelled

### Dependencies Visualization
Include a mermaid diagram showing sub-task dependencies:
```mermaid
graph TD
    A[ST-T-001-001: Task Entity] --> B[ST-T-001-002: Task Service]
    A --> C[ST-T-001-003: Local Storage]
    B --> D[ST-T-001-004: CLI Commands]
    C --> D
    D --> E[ST-T-001-005: Integration Tests]
```

### Implementation Sequence
Provide recommended implementation order:
```
Week 1:
- ST-T-001-001: Task Entity (Day 1)
- ST-T-001-002: Task Service (Day 2)
- ST-T-001-003: Local Storage (Day 3)

Week 2:
- ST-T-001-004: CLI Commands (Day 1-2)
- ST-T-001-005: Integration Tests (Day 3)
```

## Integration with Development Chain

### Input Sources
- **Tasks Document:** Primary source for sub-task breakdown
- **PRD Requirements:** Detailed functional requirements
- **TRD Specifications:** Technical implementation guidance
- **Architecture Patterns:** Structural requirements and constraints

### Output Usage
- **Sprint Planning:** Individual sub-task files become sprint items
- **Developer Assignment:** Sub-tasks can be assigned by file to individual developers
- **Progress Tracking:** File completion status indicates task progress
- **Code Review:** Individual sub-task files provide focused review scope
- **Project Management:** Task files can be linked to issues, PRs, and project boards

## Validation Checklist

Before finalizing sub-tasks:
- [ ] **Task Coverage:** All task requirements addressed
- [ ] **Dependency Logic:** Sub-task dependencies are logical and minimal
- [ ] **Implementation Clarity:** Each sub-task is unambiguous
- [ ] **Test Strategy:** Testing approach is comprehensive
- [ ] **Integration Points:** Clear how sub-tasks connect
- [ ] **Time Estimates:** Realistic 2-4 hour estimates
- [ ] **Definition of Done:** Clear completion criteria
- [ ] **Quality Standards:** Code quality requirements defined

## Sub-Task Categories

### Code Implementation Sub-Tasks
- Entity/model creation
- Service implementation
- API endpoint development
- Integration layer coding
- Utility function development

### Configuration Sub-Tasks
- Environment setup
- Build system configuration
- Dependency management
- Deployment configuration
- Security configuration

### Testing Sub-Tasks
- Unit test implementation
- Integration test creation
- End-to-end test development
- Performance test setup
- Security test implementation

### Documentation Sub-Tasks
- API documentation
- Code documentation
- User guide updates
- Architecture documentation
- Setup instructions

### Research Sub-Tasks
- Technology evaluation
- Library comparison
- Pattern research
- Performance analysis
- Security assessment

## Final Instructions

1. **Analyze Thoroughly:** Read tasks document completely before starting
2. **Think Granularly:** Break down into implementable chunks
3. **Be Specific:** Provide concrete implementation guidance
4. **Consider Dependencies:** Map sub-task relationships carefully
5. **Include Testing:** Every code sub-task needs testing sub-tasks
6. **Define Completion:** Clear definition of done for each sub-task
7. **Estimate Realistically:** 2-4 hours per sub-task maximum
8. **Create Individual Files:** Save each task and sub-task in separate files
9. **Update Index:** Maintain task-index.md with links to all task files
10. **Next Step:** After completing sub-tasks, teams can begin sprint planning and implementation

## Relationship to Chain

This rule completes the development chain:
1. **create-prd.mdc** → Defines business requirements and high-level phases
2. **create-trd.mdc** → Translates to technical specifications and implementation roadmap  
3. **generate-tasks.mdc** → Creates atomic, functional development phases
4. **generate-sub-tasks.mdc** → Breaks down each task into implementable sub-tasks ← **YOU ARE HERE**

The output of this rule provides the final level of detail needed for development teams to begin implementation, with each sub-task representing a concrete, actionable work item that contributes to completing the overall system defined in the PRD.