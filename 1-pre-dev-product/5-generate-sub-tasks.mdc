---
description: 
globs: 
alwaysApply: false
---
# Rule: Generating Sub-Tasks from Tasks Analysis

## 🧠 Enhanced Analysis Tools - USE THESE!

**CRITICAL:** Leverage these tools throughout the sub-task generation process:

### 🧩 Memory MCP Integration
- **Retrieve context:** `memory_search` for PRD, TRD, and task decisions to maintain consistency
- **Store implementation patterns:** `memory_store_chunk` with successful sub-task structures and patterns
- **Reference similar breakdowns:** `memory_search` for comparable sub-task implementations from past projects
- **Track development workflow:** `memory_tasks` for sub-task generation and implementation progress
- **Store decisions:** `memory_store_decision` for sub-task boundary decisions and implementation approaches
- **Tags to use:** `["sub-tasks", "implementation", "breakdown", "feature-name", "development"]`

### 🔄 Sequential Thinking MCP
- **Use for:** Complex task decomposition, dependency analysis, implementation sequencing
- **Pattern:** Task requirements → technical components → implementation steps → sub-task boundaries
- **Benefit:** Ensures sub-tasks are logically sequenced and properly sized for LLM implementation
- **When:** During task breakdown analysis, dependency mapping, and implementation planning

**IMPLEMENTATION TIP:** Each sub-task should include Memory MCP actions to store implementation progress and learnings!

**Pro tip:** Store every implementation decision and pattern to build a knowledge base of successful development approaches!

## Goal

To guide an AI assistant in analyzing tasks and breaking them down into detailed, implementable sub-tasks. Each sub-task must be specific, actionable, and small enough to be completed in a single development session while contributing to the completion of its parent task.

## Process

1. **Read Tasks Document:** The AI must first read the tasks-[feature-name].md document to understand the atomic phases from `/docs/pre-development/tasks/`
   - 🧩 **Memory Action:** `memory_search` to retrieve all related context from PRD, TRD, and validation steps
   - 🧩 **Memory Action:** `memory_tasks` to track sub-task generation workflow with session_id

2. **Verify Chain Validation:** Ensure validation-report-[feature-name].md shows PASS status and tasks are validated
   - 🧩 **Memory Action:** `memory_search` for validation patterns and any documented risks

3. **Analyze Task Structure:** Extract and understand each task's scope, dependencies, and deliverables
   - 🔄 **Sequential Thinking:** Map task boundaries to implementation components and dependencies

4. **Apply Senior Engineer Breakdown:** Ensure each sub-task is comprehensive yet focused
   - 🔄 **Sequential Thinking:** Validate each sub-task represents a full day's work (~6 hours) for a senior engineer

5. **Generate Sub-Tasks:** Create detailed sub-task specifications using the structure below
   - 🧩 **Memory Action:** `memory_store_decision` for sub-task breakdown rationale and implementation approach
6. **Optional User Review:** Since sub-tasks are implementation details, user review is optional:
   - "I've created detailed sub-tasks for implementation. Would you like to review the granularity, or shall I proceed with saving them?"
   - If user wants to review, WAIT for feedback
   - If user approves or skips review, proceed to save
   - 🧩 **Memory Action:** `memory_store_chunk` with user feedback on sub-task granularity (if provided)

7. **Save Output:** Create individual files for each task and sub-task in `/docs/pre-development/tasks/` directory (see File Organization section)
   - 🧩 **Memory Action:** `memory_create_thread` completing the full development chain: PRD → TRD → Tasks → Sub-tasks

## Input Document Analysis

### Tasks Analysis Requirements
- **Task Overview:** Extract the deliverable and atomic validation from each task
- **Functional Scope:** Understand what features are included in each task
- **Technical Scope:** Identify the technical components and architecture elements
- **Dependencies:** Map prerequisite tasks and blocking relationships
- **Acceptance Criteria:** Use acceptance criteria to guide sub-task creation

### Technical Context Requirements
- **PRD Reference:** Cross-reference with original PRD for detailed requirements
- **TRD Reference:** Leverage technical specifications for implementation details
- **Architecture Patterns:** Ensure sub-tasks align with defined architecture
- **Testing Strategy:** Include testing sub-tasks based on overall testing approach
- **Quality Standards:** Incorporate code quality and review requirements

## Sub-Task Principles

### Definition of "Implementable Sub-Task"
Each sub-task MUST be:
- **Senior Engineer Scope:** Designed for very senior, highly skilled engineers who can work efficiently
- **Full Day Session:** Approximately 6 hours of focused work (not 2-4 hours)
- **Comprehensive:** Includes multiple related components, tests, and integration
- **Self-Contained:** Complete feature slice with all necessary parts
- **Production-Ready:** Includes implementation, tests, documentation, and quality checks

### Sub-Task Validation Checklist
Before finalizing each sub-task, ensure:
- [ ] **Clear Deliverable:** Specific code, config, or documentation output
- [ ] **Implementation Path:** Obvious how to implement the requirement
- [ ] **Test Strategy:** Clear how to validate the sub-task
- [ ] **Integration Point:** Clear how it fits with other sub-tasks
- [ ] **Definition of Done:** Unambiguous completion criteria

## Sub-Task Structure

Each generated sub-task should include these sections (strictly follow this structure):

### 1. Sub-Task Overview
- **Sub-Task ID:** ST-T-[task-id]-[number] (e.g., ST-T-001-001, ST-T-001-002)
- **Sub-Task Name:** Clear, comprehensive name (e.g., "Implement Complete Task Management Domain Layer")
- **Parent Task:** Reference to task (e.g., "T-001: CLI Foundation with Local Storage")
- **Estimated Duration:** ~6 hours (full day for senior engineer)
- **Implementation Type:** Full Stack (combines Code, Tests, Integration, Documentation)

### 🔀 Git Workflow (REQUIRED)
**BEFORE STARTING:**
```bash
git checkout -b feature/ST-T-[task-id]-[num]-[short-desc]
# Example: git checkout -b feature/ST-T-001-001-task-entity
```

**AFTER COMPLETING:**
```bash
git add .
git commit -m "feat(ST-T-[task-id]-[num]): [brief description]

Implemented:
- [what was built]

Deviations:
- [any changes from plan]

Notes:
- [implementation details]"

git push -u origin feature/ST-T-[task-id]-[num]-[short-desc]
```

### 2. Deliverable Specification
- **Primary Output:** Specific files, functions, or components to create
- **Code Location:** Exact file paths and directory structure
- **File Size Guidelines:** 
  - **Target:** <300 lines per file for optimal LLM processing
  - **Maximum:** 500 lines per file (hard limit)
  - **Split Strategy:** If approaching 500 lines, break into logical modules
- **Technical Requirements:** Specific technologies, libraries, patterns to use
- **Interface Definition:** APIs, function signatures, data structures
- **Architecture Compliance:** Hexagonal Architecture pattern requirements
- **lib-commons Usage:** Required lib-commons components and utilities
- **lib-auth Integration:** Authentication/authorization requirements (for Midaz projects)

### 3. Implementation Details
- **Step-by-Step Approach:** Numbered implementation steps
- **Code Examples:** Key code snippets or structure examples
- **Configuration Changes:** Specific config files or environment changes
- **Dependencies:** Libraries, packages, or tools needed

### 4. Acceptance Criteria
- **Functional Criteria:** What the code must do
- **Technical Criteria:** Code quality, performance, security requirements
- **Integration Criteria:** How it connects with existing components
- **Test Criteria:** Specific tests that must pass

### 5. Testing Requirements
- **Unit Tests:** Specific test cases to write
  - **Go Projects:** Test files must be alongside implementation (e.g., `task.go` → `task_test.go`)
  - **Test Package:** Use same package for white-box testing or `_test` suffix for black-box
- **Integration Tests:** Integration points to test
- **Manual Testing:** Manual validation steps
- **Test Data:** Required test fixtures or data

### 6. Definition of Done
- **Code Complete:** All code written and reviewed
- **Tests Passing:** All tests written and passing
- **Documentation Updated:** Relevant docs updated
- **Integration Verified:** Works with existing components
- **Quality Checks Pass:** All language-specific quality validation complete
- **Git Workflow Complete:** Branch created, committed with implementation details and deviations
- **PR Submitted:** Pull request created against tasks-implementation branch
- **Review Approved:** Code review completed and PR merged
- **🧩 Memory Actions Complete:** Implementation progress and learnings stored in memory

### 7. Quality Assurance Requirements
**CRITICAL:** Each sub-task MUST include programming language-specific quality checks:

#### Go Projects
```bash
# Run after each sub-task completion
make fmt              # Code formatting
make vet              # Static analysis
gosec ./...          # Security analysis
govulncheck ./...    # Vulnerability check
perfsprint ./...     # Performance analysis
make lint            # Comprehensive linting
go test ./...        # Test execution

# After quality checks pass, build to ensure compilation
go build ./...       # Build verification
```

#### TypeScript/JavaScript Projects
```bash
# Run after each sub-task completion
npm run lint         # ESLint code quality
npm run typecheck    # TypeScript validation
npm test            # Test execution
npm run build       # Production build verification
```

#### Python Projects
```bash
# Run after each sub-task completion
ruff check .         # Linting and formatting
mypy .              # Type checking
pytest              # Test execution
black .             # Code formatting
```

#### Other Languages
- **Rust:** `cargo fmt && cargo clippy && cargo test`
- **Java:** `mvn compile && mvn test && mvn checkstyle:check`
- **C#:** `dotnet format && dotnet test && dotnet build`

**FAILURE PROTOCOL:** If quality checks fail:
1. Fix issues immediately before proceeding
2. Document quality violations in memory: `memory_store_chunk` with tag `quality-violation`
3. Re-run checks to ensure resolution
4. Only mark sub-task as complete when ALL quality checks pass

### 🚨 Pre-Emptive Quality Guidance (CRITICAL)

**IMPORTANT:** Use these patterns to avoid common quality check failures from the start:

#### Go Language Anti-Patterns to Avoid
**Error Handling:**
```go
// ❌ WRONG - causes errcheck/staticcheck violations
fmt.Errorf("user not found")  // For static messages

// ✅ CORRECT - use errors.New for static messages
errors.New("user not found")

// ✅ CORRECT - use fmt.Errorf only with variables
fmt.Errorf("user %s not found", userID)
```

**String Operations:**
```go
// ❌ WRONG - causes perfsprint violations
fmt.Sprintf("%d", number)     // Use strconv.Itoa(number)
fmt.Sprintf("%s", variable)   // Use string(variable) or direct concatenation
fmt.Sprintf("prefix%s", var)  // Use "prefix"+var

// ✅ CORRECT - performance optimized
strconv.Itoa(number)          // For integer to string
"prefix" + variable           // For simple concatenation
```

**Function Complexity (Prevent gocyclo/nestif violations):**
```go
// ❌ WRONG - high complexity, deep nesting
func ProcessSubTask(data SubTaskData) error {
    if data.Valid {
        if data.Type == "implementation" {
            if data.Dependencies != nil {
                if len(data.Dependencies) > 0 {
                    // Deep nesting causes nestif violations
                }
            }
        }
    }
    return nil
}

// ✅ CORRECT - early returns, guard clauses
func ProcessSubTask(data SubTaskData) error {
    if !data.Valid {
        return errors.New("invalid sub-task data")
    }
    if data.Type != "implementation" {
        return nil  // Early return reduces complexity
    }
    if data.Dependencies == nil || len(data.Dependencies) == 0 {
        return nil  // Guard clause prevents nesting
    }
    
    // Main logic here - minimal nesting
    return data.Process()
}
```

**Preallocation and Efficiency:**
```go
// ❌ WRONG - causes prealloc violations
var results []SubTaskResult
for _, task := range subTasks {
    results = append(results, processSubTask(task))
}

// ✅ CORRECT - pre-allocate slices
results := make([]SubTaskResult, 0, len(subTasks))
for _, task := range subTasks {
    results = append(results, processSubTask(task))
}
```

**Context Usage in Sub-Tasks:**
```go
// ❌ WRONG - causes unparam violations
func ExecuteSubTask(ctx context.Context, task SubTask, metadata string) error {
    // ctx and metadata never used - unparam violations
    return task.Run()
}

// ✅ CORRECT - use all parameters or remove them
func ExecuteSubTask(task SubTask) error {
    return task.Run()
}

// ✅ OR use context properly for cancellation
func ExecuteSubTask(ctx context.Context, task SubTask) error {
    select {
    case <-ctx.Done():
        return ctx.Err()
    default:
        return task.RunWithContext(ctx)
    }
}
```

#### TypeScript/JavaScript Sub-Task Patterns
```typescript
// ❌ WRONG - common sub-task implementation issues
const processSubTask = (data: any) => {              // Avoid 'any'
    let result = data.process();                     // Use const when possible
    if (result == null) return null;                 // Use === for strict equality
}

// ✅ CORRECT - type-safe sub-task implementation
const processSubTask = (data: SubTaskData): SubTaskResult | null => {
    const result = data.process();                   // const for immutable
    if (result === null) return null;                // Strict equality
    return result;
}
```

#### Python Sub-Task Patterns
```python
# ❌ WRONG - common sub-task violations
def execute_sub_task(data):                         # Missing type hints
    if hasattr(data, 'process'):                    # Unsafe attribute check
        return data.process()

# ✅ CORRECT - type-safe sub-task patterns
from typing import Protocol, Optional

class SubTaskData(Protocol):
    def process(self) -> Optional[str]: ...

def execute_sub_task(data: SubTaskData) -> Optional[str]:
    return data.process()
```

### 🎯 Sub-Task Specific Quality Strategies

**Keep Sub-Task Functions Focused:**
- **Target:** <15 lines per sub-task function
- **Maximum:** 30 lines (split if larger)
- **Strategy:** One responsibility per sub-task function

**Sub-Task Error Handling:**
```go
// ✅ RECOMMENDED pattern for sub-task error handling
func ExecuteSubTaskWithValidation(input SubTaskInput) (*SubTaskResult, error) {
    // Validate sub-task prerequisites
    if err := input.ValidatePrerequisites(); err != nil {
        return nil, fmt.Errorf("sub-task prerequisites not met: %w", err)
    }
    
    // Execute sub-task with proper error wrapping
    result, err := input.Execute()
    if err != nil {
        return nil, fmt.Errorf("sub-task execution failed: %w", err)
    }
    
    // Validate sub-task output
    if err := result.Validate(); err != nil {
        return nil, fmt.Errorf("sub-task output validation failed: %w", err)
    }
    
    return result, nil
}
```

**Avoid Common Sub-Task Anti-Patterns:**
```go
// ❌ WRONG - common sub-task implementation issues
func ProcessMultipleSubTasks(tasks []SubTask) error {
    for i := 0; i < len(tasks); i++ {               // Use range instead
        if tasks[i].Type == "critical" {
            if tasks[i].Dependencies != nil {
                if len(tasks[i].Dependencies) > 0 {  // Nested conditions
                    // Complex nested logic
                }
            }
        }
    }
    return nil
}

// ✅ CORRECT - clean sub-task processing
func ProcessMultipleSubTasks(tasks []SubTask) error {
    for _, task := range tasks {                    // Use range for cleaner iteration
        if err := processIndividualSubTask(task); err != nil {
            return fmt.Errorf("sub-task %s failed: %w", task.ID, err)
        }
    }
    return nil
}

func processIndividualSubTask(task SubTask) error {
    if task.Type != "critical" {
        return nil  // Early return for non-critical tasks
    }
    if task.Dependencies == nil || len(task.Dependencies) == 0 {
        return nil  // Guard clause prevents nesting
    }
    
    // Process critical task with dependencies
    return task.ProcessWithDependencies()
}
```

### 📏 Sub-Task File Size Guidelines

**Optimal Sub-Task File Sizes:**
- **Go sub-task files:** <200 lines target, 300 lines maximum
- **TypeScript sub-task files:** <150 lines target, 250 lines maximum
- **Python sub-task files:** <120 lines target, 200 lines maximum

**Sub-Task Decomposition Strategy:**
1. **Split by responsibility** - Each file handles one sub-task type
2. **Extract common utilities** - Shared logic goes to utility files
3. **Separate concerns** - Data processing, validation, and I/O in different files
4. **Use interfaces** - Define clear contracts between sub-task components

### 🔍 Sub-Task Pre-Implementation Quality Checklist

Before implementing any sub-task, ensure specification includes:
- [ ] **Single responsibility** - Each sub-task does one thing well
- [ ] **Clear input/output** - Well-defined interfaces and data structures
- [ ] **Error handling strategy** - Proper error propagation and context
- [ ] **Dependency management** - Clear prerequisite handling
- [ ] **Testing strategy** - Unit tests for each sub-task function
- [ ] **Performance considerations** - Efficient algorithms and data structures
- [ ] **Memory management** - Proper resource cleanup and lifecycle
- [ ] **Type safety** - Strong typing throughout sub-task implementation

### 🔄 Quality-First Sub-Task Implementation Flow

**For each sub-task implementation:**
1. **Design interfaces first** - Define clear input/output contracts
2. **Write tests before code** - TDD approach for better quality
3. **Implement with quality patterns** - Use proven patterns from the start
4. **Run quality checks frequently** - Check early and often
5. **Refactor immediately** - Fix quality issues as soon as they appear

**Sub-Task Implementation Template:**
```go
// ✅ RECOMMENDED sub-task implementation template
package subtask

import (
    "context"
    "errors"
    "fmt"
)

// SubTaskInput defines the input contract for this sub-task
type SubTaskInput struct {
    ID           string            `json:"id" validate:"required"`
    Data         map[string]any    `json:"data" validate:"required"`
    Dependencies []string          `json:"dependencies"`
}

// SubTaskResult defines the output contract for this sub-task
type SubTaskResult struct {
    ID      string         `json:"id"`
    Status  string         `json:"status"`
    Output  map[string]any `json:"output"`
    Errors  []string       `json:"errors,omitempty"`
}

// Execute implements the sub-task with proper error handling
func (input *SubTaskInput) Execute(ctx context.Context) (*SubTaskResult, error) {
    // Early validation
    if err := input.Validate(); err != nil {
        return nil, fmt.Errorf("input validation failed: %w", err)
    }
    
    // Check context cancellation
    select {
    case <-ctx.Done():
        return nil, ctx.Err()
    default:
    }
    
    // Main sub-task logic
    result := &SubTaskResult{
        ID:     input.ID,
        Status: "processing",
        Output: make(map[string]any),
    }
    
    if err := input.processData(result); err != nil {
        return nil, fmt.Errorf("data processing failed: %w", err)
    }
    
    result.Status = "completed"
    return result, nil
}

// Validate ensures input meets requirements
func (input *SubTaskInput) Validate() error {
    if input.ID == "" {
        return errors.New("sub-task ID is required")
    }
    if input.Data == nil {
        return errors.New("sub-task data is required")
    }
    return nil
}

// processData handles the core sub-task logic
func (input *SubTaskInput) processData(result *SubTaskResult) error {
    // Implementation specific to this sub-task
    // Keep this function focused and small
    return nil
}
```

### 🧠 Required Memory Actions During Implementation
**CRITICAL:** Every sub-task implementation MUST include these Memory MCP actions:

### 🔄 Sequential Thinking for Complex Sub-Tasks
**RECOMMENDED:** For complex implementation decisions, use Sequential Thinking MCP:
```
mcp__sequential-thinking__sequentialthinking
  thought="[current implementation challenge or decision point]"
  thought_number=1
  total_thoughts=3-5
  next_thought_needed=true
```
Use this when facing:
- Architecture decisions within the sub-task
- Complex algorithm implementations  
- Integration challenges
- Performance optimization choices

**Before Starting:**
```
memory_store_chunk
  content="Starting ST-[ID]: [task-name]. Context: [brief context]"
  tags=["sub-task", "started", "ST-[ID]", "feature-name"]
  session_id="[current-session]"
  repository="[project-repo]"
```

**During Implementation:**
```
memory_store_decision 
  decision="[key implementation choice made]"
  rationale="[why this approach was chosen]"
  alternatives="[other options considered]"
  session_id="[current-session]"
  repository="[project-repo]"
```

**After Completion:**
```
memory_store_chunk
  content="Completed ST-[ID]: [summary]. Deviations: [any changes]. Learnings: [insights gained]"
  tags=["sub-task", "completed", "ST-[ID]", "learnings"]
  session_id="[current-session]"
  repository="[project-repo]"
```

### 7. Dependencies and Blockers
- **Required Sub-Tasks:** Sub-tasks that must be completed first
- **External Dependencies:** Third-party services, libraries, or tools

## User Interaction Guidelines

### Optional Review Process
Since sub-tasks are implementation details, user review is optional but available:

1. **Summary Presentation:** Show task breakdown summary first
2. **Granularity Check:** Ask if level of detail is appropriate
3. **Quick Approval:** Allow user to skip detailed review

### Example Interaction Flow
```
AI: "I've broken down the main tasks into comprehensive sub-tasks for senior engineers:

**MT-001: Foundation Phase** → 3 sub-tasks
- ST-001: Complete Task Domain Layer with Repository Pattern (6h)
- ST-002: CLI Command Framework with Full Test Coverage (6h)
- ST-003: Local Storage Implementation with Migration Support (6h)

**MT-002: Core Features** → 4 sub-tasks
**MT-003: Enhancements** → 2 sub-tasks

Total: 9 implementation sub-tasks (optimized for senior engineers)

Would you like to:
1. Review the detailed breakdown
2. Adjust the scope (more comprehensive or more granular)
3. Proceed with saving these sub-tasks

What's your preference?"

[WAIT FOR USER RESPONSE - OR PROCEED IF USER SAYS "PROCEED"]

User: "Proceed with saving"

AI: "Great! I'll save all sub-tasks in the organized structure..."
```
- **Environmental Requirements:** Development environment setup needs
- **Potential Blockers:** Known issues or complications

### 8. Integration Notes
- **Component Interfaces:** How this integrates with other components
- **Data Flow:** How data moves through this component
- **Error Handling:** How errors are managed and propagated
- **Configuration Impact:** Environment or config changes needed
- **Architecture Pattern Adherence:** Specific Hexagonal Architecture requirements
- **lib-commons Integration Points:** How lib-commons utilities are leveraged
- **lib-auth Integration Points:** Authentication/authorization integration (for Midaz projects)

## Git Workflow Requirements

### For Each Sub-Task Implementation:

1. **Branch Creation:** At the start of each sub-task
   ```bash
   git checkout -b feature/ST-T-[task-id]-[num]-[short-description]
   # Example: git checkout -b feature/ST-T-001-001-task-entity
   ```

2. **Implementation:** Follow the sub-task specification

3. **Commit Requirements:** At the end of each sub-task
   ```bash
   git add .
   git commit -m "feat(ST-T-[task-id]-[num]): [implementation summary]
   
   Implemented: [what was built]
   Deviations: [any changes from original plan]
   Notes: [important implementation details]"
   ```

4. **Pull Request:** Submit PR against tasks-implementation branch
   ```bash
   git push origin feature/ST-T-[task-id]-[num]-[short-description]
   # Create PR: feature/ST-T-[task-id]-[num] → tasks-implementation
   ```

## Example Sub-Task Format

```markdown
## ST-T-001-001: Implement Complete Task Management Domain Layer

### 1. Sub-Task Overview
- **Sub-Task ID:** ST-T-001-001
- **Sub-Task Name:** Implement Complete Task Management Domain Layer
- **Parent Task:** T-001: CLI Foundation with Local Storage
- **Estimated Duration:** ~6 hours (full day for senior engineer)
- **Implementation Type:** Full Stack (Domain Models, Repository, Service Layer, Tests)

### 2. Deliverable Specification
- **Primary Output:** Complete domain layer including entities, repositories, services, and full test coverage
- **Code Locations:** 
  - `cli/internal/domain/entities/task.go` - Task entity with validation
  - `cli/internal/domain/repositories/task_repository.go` - Repository interface
  - `cli/internal/domain/services/task_service.go` - Business logic service
  - `cli/internal/infrastructure/storage/local_task_repository.go` - Local storage implementation
  - All corresponding `*_test.go` files with >90% coverage
- **Technical Requirements:** Repository pattern, service layer, comprehensive validation, error handling
- **Interface Definitions:** Task entity, TaskRepository interface, TaskService with full CRUD operations

### 3. Implementation Details
- **Step-by-Step Approach:**
  1. Create complete domain structure (`entities/`, `repositories/`, `services/`, `infrastructure/storage/`)
  2. Implement Task entity with full validation, business rules, and state management
  3. Define TaskRepository interface with all CRUD operations and query methods
  4. Implement TaskService with business logic, validation, and transaction handling
  5. Create LocalTaskRepository with file-based storage, atomic operations, and migration support
  6. Write comprehensive unit tests for all components (>90% coverage)
  7. Add integration tests for the complete domain layer
  8. Create benchmark tests for performance validation

- **Code Examples:**
  ```go
  // Task entity with full functionality
  type Task struct {
      ID          string    `json:"id" validate:"required,uuid"`
      Content     string    `json:"content" validate:"required,min=1,max=1000"`
      Status      Status    `json:"status" validate:"required,oneof=pending in_progress completed cancelled"`
      Priority    Priority  `json:"priority" validate:"required,oneof=low medium high"`
      Repository  string    `json:"repository" validate:"required"`
      Tags        []string  `json:"tags"`
      Metadata    map[string]interface{} `json:"metadata"`
      CreatedAt   time.Time `json:"created_at"`
      UpdatedAt   time.Time `json:"updated_at"`
      CompletedAt *time.Time `json:"completed_at,omitempty"`
  }
  
  // Repository interface with comprehensive operations
  type TaskRepository interface {
      Create(ctx context.Context, task *Task) error
      GetByID(ctx context.Context, id string) (*Task, error)
      List(ctx context.Context, filter TaskFilter) ([]*Task, error)
      Update(ctx context.Context, task *Task) error
      Delete(ctx context.Context, id string) error
      Count(ctx context.Context, filter TaskFilter) (int, error)
      BeginTransaction(ctx context.Context) (Transaction, error)
  }
  
  // Service layer with business logic
  type TaskService struct {
      repo TaskRepository
      validator *validator.Validate
      eventBus EventBus
  }
  ```

- **Configuration Changes:** Setup for local storage paths, file permissions, migration settings
- **Dependencies:** 
  - `github.com/go-playground/validator/v10`
  - `github.com/google/uuid`
  - `github.com/stretchr/testify`
  - `github.com/spf13/afero` (for file system abstraction in tests)

### 4. Acceptance Criteria
- **Functional Criteria:**
  - Complete domain layer implements all PRD requirements
  - Task lifecycle (create, update, status transitions) fully supported
  - Repository pattern provides clean data access abstraction
  - Service layer enforces all business rules and validations
  - Local storage provides persistent, atomic data operations
  
- **Technical Criteria:**
  - Code follows Go conventions, SOLID principles, and clean architecture
  - All public APIs have comprehensive documentation
  - Error handling provides context and recovery options
  - Performance meets requirements (<10ms for single operations)
  - Memory usage is optimized (no leaks, efficient data structures)
  
- **Integration Criteria:**
  - Domain layer can be used by CLI, API, or other interfaces
  - Repository interface allows easy swapping of storage implementations
  - Service layer provides transaction support
  - Event system allows for future extensions
  
- **Test Criteria:**
  - Unit test coverage >90% for all components
  - Integration tests verify complete workflows
  - Benchmark tests validate performance requirements
  - Test fixtures cover edge cases and error scenarios

### 5. Testing Requirements
- **Unit Tests (per component):**
  - Task Entity: validation rules, state transitions, business logic
  - TaskRepository Interface: mock implementations for testing
  - TaskService: business logic, validation, error handling
  - LocalTaskRepository: CRUD operations, transactions, migrations
  - Coverage requirement: >90% per file

- **Integration Tests:**
  - Complete task lifecycle (create → update → complete → delete)
  - Concurrent operations handling
  - Transaction rollback scenarios
  - Data persistence and recovery
  - Migration from older versions

- **Performance Tests:**
  - Benchmark CRUD operations
  - Stress test with 10,000+ tasks
  - Concurrent access patterns
  - Memory usage profiling

- **Test Data:**
  - Fixtures for all task states and priorities
  - Edge cases (max length content, special characters)
  - Invalid data for error testing
  - Large datasets for performance testing

### 6. Definition of Done
- **Code Complete:** Complete domain layer implemented (entities, repositories, services, storage)
- **Tests Passing:** All unit, integration, and benchmark tests passing (>90% coverage)
- **Documentation Updated:** Comprehensive godoc for all public APIs, README for domain layer
- **Integration Verified:** Domain layer successfully integrated with CLI or test harness
- **Performance Validated:** All operations meet performance requirements
- **Quality Checks Pass:** All Go quality tools pass (fmt, vet, lint, gosec, etc.)
- **Git Workflow Complete:** Feature branch with clean commit history, PR created
- **Review Approved:** Code review completed with all feedback addressed
- **Memory Actions Complete:** Implementation decisions and patterns stored

### 7. Dependencies and Blockers
- **Required Sub-Tasks:** None (foundational task)
- **External Dependencies:** Go validation library
- **Environmental Requirements:** Go 1.23+ development environment
- **Potential Blockers:** Validation library compatibility issues

### 8. Integration Notes
- **Component Interfaces:** Used by TaskService in domain layer
- **Data Flow:** Created from CLI input, stored via Storage interface
- **Error Handling:** Returns structured validation errors
- **Configuration Impact:** None
```

## Quality Standards

### Granularity Validation
Each sub-task must:
- [ ] **Single Purpose:** Addresses one specific implementation concern
- [ ] **Time-Bounded:** Can be completed in one development session
- [ ] **Clear Output:** Produces identifiable deliverable
- [ ] **Testable Scope:** Can be validated independently
- [ ] **Integration Ready:** Fits cleanly with other sub-tasks

### Implementation Readiness
Verify each sub-task:
- [ ] **Technical Clarity:** No ambiguity about what to implement
- [ ] **Architecture Alignment:** Follows established patterns
- [ ] **Dependency Management:** Clear prerequisite relationships
- [ ] **Test Coverage:** Testing approach clearly defined
- [ ] **Error Handling:** Error scenarios considered

## Output Structure

### File Organization

**IMPORTANT: Each task and sub-task must be saved in separate files for simplified management.**

```
docs/pre-development/tasks/
├── tasks-[feature-name].md                        # Input document (overview)
├── T-[id]/                                         # Directory per task
│   ├── task.md                                    # Task specification
│   ├── ST-T-[id]-[num].md                         # Individual sub-task files
│   ├── ST-T-[id]-[num].md
│   └── ...
├── task-dependencies.md                            # Cross-task dependency mapping
├── implementation-checklist.md                     # Overall progress tracking
└── task-index.md                                  # Index of all tasks and sub-tasks
```

**File Naming Convention:**
- Tasks: `docs/pre-development/tasks/T-[id]/task.md` (e.g., `T-001/task.md`)
- Sub-Tasks: `docs/pre-development/tasks/T-[id]/ST-T-[id]-[num].md` (e.g., `T-001/ST-T-001-001.md`)
- Dependencies: `docs/pre-development/tasks/task-dependencies.md`
- Index: `docs/pre-development/tasks/task-index.md`

**Benefits of Individual Files:**
- **Simplified Management:** Each task can be tracked, assigned, and updated independently
- **Version Control:** Clean git history with granular changes per task
- **Parallel Development:** Multiple developers can work on different sub-tasks simultaneously
- **Progress Tracking:** Individual file status reflects completion state
- **Code Review:** Focused reviews per sub-task rather than large documents

### Task Index File Structure

Create `docs/pre-development/tasks/task-index.md` to maintain an overview of all tasks:

```markdown
# Task Index - [Feature Name]

## Tasks Overview

| Task ID | Status | Name | Sub-Tasks | Estimated Total |
|---------|--------|------|-----------|-----------------|
| T-001 | In Progress | CLI Foundation | 5 | 16 hours |
| T-002 | Pending | PRD Processing | 6 | 20 hours |
| T-003 | Pending | Server Integration | 4 | 14 hours |

## Sub-Tasks by Task

### T-001: CLI Foundation
- [x] [ST-T-001-001](mdc:T-001/ST-T-001-001.md): Complete Task Domain Layer (6h) - ✅ Complete
- [ ] [ST-T-001-002](mdc:T-001/ST-T-001-002.md): CLI Command Framework with Tests (6h) - 🔄 In Progress
- [ ] [ST-T-001-003](mdc:T-001/ST-T-001-003.md): Local Storage & Migration System (6h) - ⏳ Pending

**Progress:** 1/3 Complete (33%)
```

**Status Icons:**
- ✅ Complete
- 🔄 In Progress
- ⏳ Pending
- ❌ Blocked
- 🚫 Cancelled

### Dependencies Visualization
Include a mermaid diagram showing sub-task dependencies:
```mermaid
graph TD
    A[ST-T-001-001: Task Entity] --> B[ST-T-001-002: Task Service]
    A --> C[ST-T-001-003: Local Storage]
    B --> D[ST-T-001-004: CLI Commands]
    C --> D
    D --> E[ST-T-001-005: Integration Tests]
```

### Implementation Sequence
Provide recommended implementation order:
```
Week 1:
- ST-T-001-001: Complete Task Domain Layer (Day 1)
- ST-T-001-002: CLI Command Framework with Tests (Day 2)
- ST-T-001-003: Local Storage & Migration System (Day 3)

Week 2:
- ST-T-002-001: API Layer with Authentication (Day 1)
- ST-T-002-002: Advanced Features & Integration (Day 2)
- ST-T-002-003: Performance Optimization & Polish (Day 3)
```

## Integration with Development Chain

### Input Sources
- **Tasks Document:** Primary source for sub-task breakdown
- **PRD Requirements:** Detailed functional requirements
- **TRD Specifications:** Technical implementation guidance
- **Architecture Patterns:** Structural requirements and constraints

### Output Usage
- **Sprint Planning:** Individual sub-task files become sprint items
- **Developer Assignment:** Sub-tasks can be assigned by file to individual developers
- **Progress Tracking:** File completion status indicates task progress
- **Code Review:** Individual sub-task files provide focused review scope
- **Project Management:** Task files can be linked to issues, PRs, and project boards

## Validation Checklist

Before finalizing sub-tasks:
- [ ] **Task Coverage:** All task requirements addressed
- [ ] **Dependency Logic:** Sub-task dependencies are logical and minimal
- [ ] **Implementation Clarity:** Each sub-task is unambiguous
- [ ] **Test Strategy:** Testing approach is comprehensive
- [ ] **Integration Points:** Clear how sub-tasks connect
- [ ] **Time Estimates:** Realistic ~6 hour estimates for senior engineers
- [ ] **Definition of Done:** Clear completion criteria
- [ ] **Quality Standards:** Code quality requirements defined

## Sub-Task Categories

### Code Implementation Sub-Tasks
- Entity/model creation
- Service implementation
- API endpoint development
- Integration layer coding
- Utility function development

### Configuration Sub-Tasks
- Environment setup
- Build system configuration
- Dependency management
- Deployment configuration
- Security configuration

### Testing Sub-Tasks
- Unit test implementation
- Integration test creation
- End-to-end test development
- Performance test setup
- Security test implementation

### Documentation Sub-Tasks
- API documentation
- Code documentation
- User guide updates
- Architecture documentation
- Setup instructions

### Research Sub-Tasks
- Technology evaluation
- Library comparison
- Pattern research
- Performance analysis
- Security assessment

## Final Instructions

1. **Analyze Thoroughly:** Read tasks document completely before starting
2. **Think Comprehensively:** Create full-stack sub-tasks that deliver complete functionality
3. **Be Specific:** Provide concrete implementation guidance for senior engineers
4. **Consider Dependencies:** Map sub-task relationships carefully
5. **Include Everything:** Each sub-task includes implementation, tests, docs, and quality checks
6. **Define Completion:** Clear definition of done for each comprehensive sub-task
7. **Estimate for Seniors:** ~6 hours per sub-task for very senior, highly skilled engineers
8. **Create Individual Files:** Save each task and sub-task in separate files
9. **Update Index:** Maintain task-index.md with links to all task files
10. **Next Step:** After completing sub-tasks, teams can begin sprint planning and implementation

## Relationship to Chain

This rule completes the development chain:
1. **create-prd.mdc** → Defines business requirements and high-level phases
2. **create-trd.mdc** → Translates to technical specifications and implementation roadmap  
3. **generate-tasks.mdc** → Creates atomic, functional development phases
4. **generate-sub-tasks.mdc** → Breaks down each task into implementable sub-tasks ← **YOU ARE HERE**

The output of this rule provides the final level of detail needed for development teams to begin implementation, with each sub-task representing a concrete, actionable work item that contributes to completing the overall system defined in the PRD.