---
description: 
globs: 
alwaysApply: false
---
# Rule: Generating Tasks from PRD and TRD Analysis

## 🧠 Enhanced Analysis Tools - USE THESE!

**CRITICAL:** Leverage these tools throughout the task generation process:

### 🧩 Memory MCP Integration
- **Retrieve context:** `memory_search` for PRD and TRD decisions, patterns, and constraints
- **Store task logic:** `memory_store_decision` for task breakdown rationale and dependencies
- **Reference implementations:** `memory_search` for similar task structures from past projects
- **Track progress:** `memory_tasks` for task generation workflow and user feedback
- **Tags to use:** `["tasks", "breakdown", "atomic", "feature-name", "implementation"]`

### 🔄 Sequential Thinking MCP
- **Use for:** Complex dependency analysis, task prioritization, atomic validation
- **Pattern:** Requirements → technical components → task boundaries → dependency mapping
- **Benefit:** Ensures tasks are truly atomic and deliver working software increments
- **When:** During task boundary definition and dependency analysis

**Pro tip:** Store task breakdown decisions to improve future task generation accuracy!

## Goal

To guide an AI assistant in analyzing both Product Requirements Document (PRD) and Technical Requirements Document (TRD) to generate atomic, functional tasks (phases) that serve as the foundation for project implementation. Each task must deliver a complete, working, and testable application increment.

## Process

1. **Read Both Documents:** The AI must first read both the PRD and TRD documents for comprehensive understanding from `/docs/pre-development/`
   - 🧩 **Memory Action:** `memory_search` to retrieve related PRD and TRD decisions
   - 🧩 **Memory Action:** `memory_tasks` to track task generation workflow with session_id

2. **Verify Chain Validation:** Ensure validation-report-[feature-name].md shows PASS status before proceeding (if exists)
   - 🧩 **Memory Action:** `memory_search` for validation patterns and common issues

3. **Analyze Development Roadmap:** Extract and understand the phases outlined in both PRD and TRD
   - 🔄 **Sequential Thinking:** Map requirements to implementation phases and identify dependencies

4. **Apply Atomic Principles:** Ensure each task is self-contained and delivers working functionality
   - 🔄 **Sequential Thinking:** Validate each task can stand alone and deliver user value

5. **Generate Task Breakdown:** Create detailed task specifications using the structure below
   - 🧩 **Memory Action:** `memory_store_decision` for task boundaries and atomic validation logic
6. **Request User Review:** Present task breakdown and ask for feedback:
   - "Please review this task breakdown. Would you like to adjust the prioritization or scope of any tasks?"
   - **WAIT for user feedback on task organization**
   - 🧩 **Memory Action:** `memory_store_chunk` with user feedback on task structure

7. **Incorporate Feedback:** Adjust task structure based on user preferences
   - 🧩 **Memory Action:** `memory_store_decision` documenting task adjustments and rationale

8. **Save Output:** After approval, save as `tasks-[feature-name].md` in `/docs/pre-development/tasks/` directory
   - 🧩 **Memory Action:** `memory_create_thread` linking PRD → TRD → Tasks for full context chain

## Input Documents Analysis

### PRD Analysis Requirements
- **Development Roadmap (Section 13):** Extract the high-level phases and their scope
- **Logical Dependency Chain (Section 14):** Understand the foundation-first approach
- **Functional Requirements (Section 5):** Map requirements to deliverable phases
- **User Stories (Section 3):** Identify user value delivery points
- **Success Metrics (Section 9):** Define measurable outcomes for each task

### TRD Analysis Requirements
- **Implementation Roadmap (Section 16):** Extract technical phases and dependencies
- **Component Design (Section 6):** Understand technical component breakdown
- **Technology Stack (Section 3):** Identify technical deliverables
- **Testing Strategy (Section 12):** Ensure each phase includes testing
- **Deployment Architecture (Section 13):** Define deployment milestones

## Atomic Phase Principles

### Definition of "Atomic"
Each task MUST be:
- **Self-Contained:** Can be developed, tested, and deployed independently
- **Functional:** Delivers working software that users can interact with
- **Testable:** Has clear acceptance criteria and can be validated
- **Deployable:** Results in a runnable application (even if limited scope)
- **Valuable:** Provides measurable user or business value

### Phase Validation Checklist
Before finalizing each task, ensure:
- [ ] **Independent Deployment:** Can be deployed without dependencies on future phases
- [ ] **User Interaction:** Users can perform meaningful actions with this phase alone
- [ ] **Complete Feature Set:** All components needed for the phase are included
- [ ] **Quality Standards:** Testing, monitoring, and observability are included
- [ ] **Rollback Capability:** Can be safely rolled back if issues arise

## User Interaction Guidelines

### Task Review Points
1. **After Task Generation:** Present complete task breakdown and WAIT for feedback
2. **Priority Discussion:** Allow user to adjust task order or dependencies
3. **Scope Refinement:** User can split or combine tasks as needed

### Example Interaction Flow
```
AI: "Based on the PRD and TRD, I've created the following atomic task breakdown:

**MT-001: Foundation Phase** (2 weeks)
- Basic application structure with authentication
- Delivers: Working login system

**MT-002: Core Feature Phase** (3 weeks)  
- Implement primary business logic
- Delivers: Main user workflow

**MT-003: Enhancement Phase** (2 weeks)
- Add advanced features
- Delivers: Complete feature set

Would you like to adjust the prioritization or scope of any tasks?"

[WAIT FOR USER RESPONSE]

User: "Can we split MT-002 into two smaller tasks?"

AI: "Certainly! Let me restructure MT-002 into two atomic tasks..."
```

## Task Structure

Each generated task should include these sections (strictly follow this structure):

### 1. Task Overview
- **Task ID:** MT-[number] (e.g., MT-001, MT-002)
- **Task Name:** Clear, descriptive name (e.g., "CLI Foundation with Local Storage")
- **Phase Type:** Foundation, Core Feature, Enhancement, Integration, Production
- **Duration Estimate:** Rough timeline (e.g., "4-6 weeks")
- **Atomic Validation:** Confirm this delivers a working application

### 🔀 Git Workflow for Implementation
**CRITICAL:** Each task will be broken into sub-tasks. Each sub-task MUST:
1. **Create branch:** `git checkout -b feature/ST-MT-[task-id]-[num]-[desc]`
2. **Implement** the sub-task requirements
3. **Commit with details:** Include implementation notes and any deviations
4. **Push and PR:** Create pull request for code review before merging

### 2. Deliverable Description
- **Primary Deliverable:** What working software will be delivered
- **User Value:** How users benefit from this phase
- **Business Value:** What business objective this achieves
- **Working Definition:** Exact criteria for "working application"

### 3. Functional Scope
- **Included Features:** Specific features implemented in this phase
- **User Capabilities:** What users can accomplish with this phase
- **API Endpoints:** Which endpoints are functional (if applicable)
- **UI Components:** Which interface elements are working (if applicable)

### 4. Technical Scope
- **Architecture Components:** Which technical components are built
- **Data Model:** What data structures are implemented
- **Integration Points:** Which integrations are functional
- **Infrastructure:** What deployment infrastructure is required
- **File Organization:** Target <300 lines per file, max 500 lines (split logically if larger)
- **Architecture Patterns:** Hexagonal Architecture compliance requirements
- **lib-commons Integration:** Required lib-commons components and patterns
- **lib-auth Integration:** Authentication and authorization patterns (for Midaz projects)

### 5. Dependencies
- **Required Previous Phases:** Which tasks must be completed first
- **External Dependencies:** Third-party services, libraries, or tools needed
- **Internal Dependencies:** Existing system components required
- **Blocking Dependencies:** What could prevent this phase from starting

### 6. Acceptance Criteria
- **Functional Criteria:** Numbered list of functional requirements
- **Technical Criteria:** Numbered list of technical requirements
- **Quality Criteria:** Performance, security, and reliability standards
- **User Acceptance:** How users will validate the deliverable

### 7. Testing Requirements
- **Unit Testing:** Required unit test coverage and scope
- **Integration Testing:** Integration points that must be tested
- **Cross-Task Integration:** How this task integrates with previous completed tasks
- **End-to-End Testing:** Complete user workflows to validate
- **Performance Testing:** Load and performance validation requirements
- **System Integration:** Full system validation with all completed tasks

### 8. Deployment Definition
- **Deployment Target:** Where this phase will be deployed
- **Configuration:** Required environment configuration
- **Data Migration:** Any data migration requirements
- **Rollback Plan:** How to safely revert this deployment

### 9. Success Metrics
- **Technical Metrics:** Performance, uptime, error rates
- **User Metrics:** Usage, adoption, satisfaction indicators
- **Business Metrics:** Revenue, efficiency, cost impact
- **Quality Metrics:** Code coverage, bug rates, security compliance

### 10. Risk Assessment
- **Technical Risks:** Implementation challenges and mitigations
- **Integration Risks:** Potential integration issues
- **Timeline Risks:** Factors that could affect delivery
- **Quality Risks:** Potential quality or performance issues

### 11. Quality Assurance Requirements
**CRITICAL:** Each task and sub-task MUST include programming language-specific quality checks:

#### Go Projects
```bash
# Run after each task/sub-task completion
make fmt              # Code formatting
make vet              # Static analysis
gosec ./...          # Security analysis
govulncheck ./...    # Vulnerability check
perfsprint ./...     # Performance analysis
make lint            # Comprehensive linting
go test ./...        # Test execution

# After quality checks pass, build to ensure compilation
go build ./...       # Build verification
```

#### TypeScript/JavaScript Projects
```bash
# Run after each task/sub-task completion
npm run lint         # ESLint code quality
npm run typecheck    # TypeScript validation
npm test            # Test execution
npm run build       # Production build verification
```

#### Python Projects
```bash
# Run after each task/sub-task completion
ruff check .         # Linting and formatting
mypy .              # Type checking
pytest              # Test execution
black .             # Code formatting
```

#### Other Languages
- **Rust:** `cargo fmt && cargo clippy && cargo test`
- **Java:** `mvn compile && mvn test && mvn checkstyle:check`
- **C#:** `dotnet format && dotnet test && dotnet build`

**FAILURE PROTOCOL:** If quality checks fail:
1. Fix issues immediately before proceeding
2. Document quality violations in memory: `memory_store_chunk` with tag `quality-violation`
3. Re-run checks to ensure resolution
4. Only mark task as complete when ALL quality checks pass

### 🚨 Pre-Emptive Quality Guidance (CRITICAL)

**IMPORTANT:** Use these patterns to avoid common quality check failures from the start:

#### Go Language Anti-Patterns to Avoid
**Error Handling:**
```go
// ❌ WRONG - causes errcheck/staticcheck violations
fmt.Errorf("user not found")  // For static messages

// ✅ CORRECT - use errors.New for static messages
errors.New("user not found")

// ✅ CORRECT - use fmt.Errorf only with variables
fmt.Errorf("user %s not found", userID)
```

**String Operations:**
```go
// ❌ WRONG - causes perfsprint violations
fmt.Sprintf("%d", number)     // Use strconv.Itoa(number)
fmt.Sprintf("%s", variable)   // Use string(variable) or direct concatenation
fmt.Sprintf("prefix%s", var)  // Use "prefix"+var

// ✅ CORRECT - performance optimized
strconv.Itoa(number)          // For integer to string
"prefix" + variable           // For simple concatenation
```

**Function Complexity (Prevent gocyclo/nestif violations):**
```go
// ❌ WRONG - high complexity, deep nesting
func ProcessTask(task Task) error {
    if task.Valid {
        if task.Type == "important" {
            if task.Priority > 5 {
                if task.Assignee != "" {
                    // Deep nesting causes nestif violations
                    // Complex logic causes gocyclo violations
                }
            }
        }
    }
    return nil
}

// ✅ CORRECT - early returns, guard clauses
func ProcessTask(task Task) error {
    if !task.Valid {
        return errors.New("invalid task")
    }
    if task.Type != "important" {
        return nil  // Early return reduces complexity
    }
    if task.Priority <= 5 {
        return nil  // Guard clause prevents nesting
    }
    if task.Assignee == "" {
        return errors.New("task requires assignee")
    }
    
    // Main logic here - minimal nesting
    return task.Process()
}
```

**Preallocation (Prevent performance issues):**
```go
// ❌ WRONG - causes prealloc violations
var items []Item
for i := 0; i < count; i++ {
    items = append(items, createItem(i))
}

// ✅ CORRECT - pre-allocate slices
items := make([]Item, 0, count)  // Pre-allocate capacity
for i := 0; i < count; i++ {
    items = append(items, createItem(i))
}
```

**Unused Code Prevention:**
```go
// ❌ WRONG - causes unparam/unused violations
func ProcessData(ctx context.Context, data []byte, unused string) error {
    // ctx never used - unparam violation
    // unused parameter - unparam violation
    return processBytes(data)
}

// ✅ CORRECT - use all parameters or remove them
func ProcessData(data []byte) error {
    return processBytes(data)
}

// ✅ OR use context explicitly
func ProcessData(ctx context.Context, data []byte) error {
    select {
    case <-ctx.Done():
        return ctx.Err()
    default:
        return processBytes(data)
    }
}
```

#### TypeScript/JavaScript Anti-Patterns
```typescript
// ❌ WRONG - common linting violations
const data: any = fetchData();              // Avoid 'any' type
let variable = "test";                      // Use const when possible
if (condition == true)                      // Use === instead of ==

// ✅ CORRECT - lint-compliant patterns
const data: UserData = await fetchData();  // Explicit typing
const variable = "test";                    // const for immutable
if (condition === true)                     // Strict equality
```

#### Python Anti-Patterns
```python
# ❌ WRONG - common ruff/mypy violations
def process_data(data):                     # Missing type hints
    return data.get("value")                # Unsafe dict access

# ✅ CORRECT - type-safe patterns
def process_data(data: Dict[str, Any]) -> Optional[str]:
    return data.get("value")
```

### 🎯 Complexity Management Strategies

**Keep Functions Small:**
- **Target:** <20 lines per function
- **Maximum:** 50 lines (split if larger)
- **Strategy:** Extract helper functions for complex logic

**Reduce Cognitive Complexity:**
- **Use early returns** instead of nested if statements
- **Extract validation logic** into separate functions
- **Use guard clauses** to handle edge cases first
- **Limit nesting depth** to maximum 3 levels

**Error Handling Patterns:**
```go
// ✅ RECOMMENDED pattern for Go error handling
func ProcessWithValidation(input Input) (*Result, error) {
    if err := input.Validate(); err != nil {
        return nil, fmt.Errorf("validation failed: %w", err)
    }
    
    result, err := input.Process()
    if err != nil {
        return nil, fmt.Errorf("processing failed: %w", err)
    }
    
    return result, nil
}
```

### 📏 File Size Guidelines for Quality

**Optimal File Sizes:**
- **Go files:** <300 lines target, 500 lines maximum
- **TypeScript:** <250 lines target, 400 lines maximum  
- **Python:** <200 lines target, 350 lines maximum

**When approaching limits:**
1. Extract separate modules/packages
2. Split into logical components
3. Create helper/utility files
4. Use composition over inheritance

### 🔍 Pre-Implementation Quality Checklist

Before writing any code, ensure tasks specify:
- [ ] **Error handling strategy** - Use proper error patterns
- [ ] **Function complexity limits** - Maximum 3 levels of nesting
- [ ] **Parameter usage** - All parameters must be used or explicitly ignored
- [ ] **String operation efficiency** - Use appropriate string functions
- [ ] **Slice preallocation** - Pre-allocate when size is known
- [ ] **Type safety** - Explicit types in TypeScript, type hints in Python
- [ ] **Security considerations** - Input validation, output sanitization

## Example Task Format

```markdown
## MT-001: CLI Foundation with Local Storage

### 1. Task Overview
- **Task ID:** MT-001
- **Task Name:** CLI Foundation with Local Storage
- **Phase Type:** Foundation
- **Duration Estimate:** 4-6 weeks
- **Atomic Validation:** ✅ Delivers a working CLI that can manage tasks locally

### 2. Deliverable Description
- **Primary Deliverable:** Functional CLI application that manages tasks with local file storage
- **User Value:** Developers can create, list, update, and complete tasks locally
- **Business Value:** Provides immediate task management capability without server dependency
- **Working Definition:** CLI responds to all basic commands and persists data locally

### 3. Functional Scope
- **Included Features:**
  - Task creation (`lmmc add "task description"`)
  - Task listing (`lmmc list`)
  - Task status updates (`lmmc start`, `lmmc done`)
  - Local configuration management
  - Shell completion installation
- **User Capabilities:**
  - Create new tasks with descriptions
  - View all tasks with status filtering
  - Mark tasks as started or completed
  - Configure CLI settings
- **API Endpoints:** N/A (local-only phase)
- **UI Components:** Terminal CLI interface with colored output

[Continue with remaining sections...]
```

## Quality Standards

### Completeness Validation
Each task must include:
- [ ] **Clear Success Definition:** Unambiguous criteria for completion
- [ ] **User Workflow:** Complete user journey from start to finish
- [ ] **Technical Architecture:** All required components identified
- [ ] **Testing Strategy:** Comprehensive testing plan
- [ ] **Deployment Plan:** Clear deployment and validation process

### Atomic Validation
Verify each task:
- [ ] **Standalone Value:** Provides value without future phases
- [ ] **Complete Feature Set:** All components needed are included
- [ ] **Working Software:** Results in functional, testable application
- [ ] **User-Facing:** Users can interact with and benefit from the deliverable
- [ ] **Production-Ready:** Includes monitoring, logging, and observability
- [ ] **Deployable:** Complete deployment process defined

## Task Deployment Workflow

### Git Workflow for Tasks (Atomic Phases):

1. **Task Branch:** Create tasks-implementation branch for each task
   ```bash
   git checkout -b tasks-implementation/T-[task-id]-[short-name]
   # Example: git checkout -b tasks-implementation/T-001-cli-foundation
   ```

2. **Sub-Task Integration:** All sub-task PRs merge into tasks-implementation branch

3. **Task Completion:** When all sub-tasks are complete:
   ```bash
   # Verify working deployment
   make build && make test && make deploy-staging
   
   # Create PR to develop
   git push origin tasks-implementation/T-[task-id]-[short-name]
   # Create PR: tasks-implementation/T-[task-id] → develop
   ```

4. **Task PR Requirements:**
   - Complete working application increment
   - All tests passing
   - Deployment verified
   - Documentation updated
   - Architecture compliance verified
   - Integration testing with previous tasks completed

## Output Structure

### File Organization
```
docs/pre-development/tasks/
├── tasks-[feature-name].md     # This document
├── phase-dependencies.md            # Dependency visualization
└── acceptance-checklist.md          # Validation checklist
```

### Dependencies Visualization
Include a mermaid diagram showing phase dependencies:
```mermaid
graph TD
    A[MT-001: CLI Foundation] --> B[MT-002: AI Integration]
    B --> C[MT-003: Server Integration]
    C --> D[MT-004: Advanced Features]
    D --> E[MT-005: Production Deployment]
```

## Cross-Task Integration Strategy

### Integration Testing Approach

**After Each Task Completion:**
1. **Backward Compatibility:** Ensure new task doesn't break previous tasks
2. **API Compatibility:** Verify interface contracts remain stable
3. **Data Flow Validation:** Test data flow through completed system
4. **Performance Impact:** Measure system performance with new task
5. **User Journey Testing:** Validate complete user workflows

**Integration Test Types:**
- **API Integration:** Test endpoints work together
- **Data Integration:** Verify data consistency across tasks
- **UI Integration:** Ensure seamless user experience
- **Performance Integration:** System-wide performance validation
- **Security Integration:** End-to-end security validation

**Integration Environments:**
- **Integration Environment:** Dedicated environment for cross-task testing
- **Staging Environment:** Production-like environment for final validation
- **Performance Environment:** Dedicated environment for load testing

### Integration Documentation

**Required for Each Task:**
- **Integration Points:** How this task connects to previous tasks
- **Interface Contracts:** APIs, data formats, communication protocols
- **Integration Tests:** Specific tests to validate cross-task functionality
- **Rollback Procedures:** How to safely revert if integration fails
- **Performance Benchmarks:** Expected system performance with this task

## Integration with Development Chain

### Input Sources
- **PRD Section 13:** Development Roadmap phases
- **PRD Section 14:** Logical Dependency Chain
- **TRD Section 16:** Implementation Roadmap
- **User Stories:** Value delivery validation

### Output Usage
- **generate-sub-tasks.mdc:** Uses tasks to create detailed sub-tasks
- **Project Planning:** Provides sprint/milestone boundaries
- **Team Coordination:** Defines handoff points between teams
- **Stakeholder Communication:** Shows delivery milestones
- **Integration Testing:** Provides framework for cross-task integration

## Validation Checklist

Before finalizing tasks:
- [ ] **PRD Alignment:** All PRD phases represented in tasks
- [ ] **TRD Alignment:** Technical roadmap matches task structure
- [ ] **Atomic Principle:** Each task delivers working software
- [ ] **Dependency Logic:** Dependencies are logical and minimal
- [ ] **User Value:** Each phase provides measurable user benefit
- [ ] **Technical Completeness:** All required components included
- [ ] **Testing Coverage:** Comprehensive testing strategy defined
- [ ] **Deployment Readiness:** Clear deployment and validation plan

## Final Instructions

1. **Read Both Documents:** Always analyze both PRD and TRD thoroughly
2. **Apply Atomic Thinking:** Each task must be a complete, working increment
3. **Validate Dependencies:** Ensure dependencies are necessary and minimal
4. **Define Success Clearly:** Each task must have unambiguous completion criteria
5. **Include Quality Measures:** Testing, monitoring, and observability in every phase
6. **Plan for Users:** Each phase should provide tangible user value
7. **Next Step:** After completing tasks, use `@generate-sub-tasks.mdc` for detailed breakdown

## Relationship to Chain

This rule is the third step in the development chain:
1. **create-prd.mdc** → Defines business requirements and high-level phases
2. **create-trd.mdc** → Translates to technical specifications and implementation roadmap
3. **generate-tasks.mdc** → Creates atomic, functional development phases ← **YOU ARE HERE**
4. **generate-sub-tasks.mdc** → Breaks down each task into implementable sub-tasks