---
description: Convert feature brief and technical approach into atomic implementation tasks
globs: 
alwaysApply: false
---
# Rule: Creating Feature Implementation Plan

## 🧠 Enhanced Analysis Tools - USE THESE!

**CRITICAL:** Leverage these tools throughout the implementation planning process:

### 🧩 Memory MCP Integration
- **Retrieve context:** `memory_search` for feature brief, technical approach, and related decisions
- **Store task logic:** `memory_store_decision` for task breakdown rationale and implementation sequencing
- **Reference implementations:** `memory_search` for similar feature implementations and successful patterns
- **Track progress:** `memory_tasks` for implementation planning workflow
- **Store patterns:** `memory_store_chunk` with successful task structures for future features
- **Tags to use:** `["implementation-plan", "feature-tasks", "breakdown", "feature-name", "development"]`

### 🔄 Sequential Thinking MCP
- **Use for:** Complex task decomposition, dependency analysis, implementation sequencing
- **Pattern:** Technical approach → implementation components → task boundaries → git workflow
- **Benefit:** Ensures tasks are atomic, properly sequenced, and efficiently implementable
- **When:** During task boundary analysis and dependency mapping

### 🧠 Zen MCP Tools (TASK OPTIMIZATION)
**Use Zen for intelligent task breakdown:**
- **`mcp__zen__analyze`** - Analyze code structure for logical boundaries
  ```bash
  mcp__zen__analyze
    files=["relevant/source/files"]
    prompt="Identify natural boundaries for implementing [feature] as separate deliverables"
    model="flash"
    analysis_type="general"
  ```
- **`mcp__zen__chat`** - Validate task sizing and dependencies
  ```bash
  mcp__zen__chat
    prompt="Review this task breakdown for [feature]. Are these deliverables appropriately sized for 2-8 hour implementation?"
    model="flash"
  ```

### 🚀 Task Tool (IMPLEMENTATION PATTERNS)
**Use Task for finding implementation examples:**
```bash
Task(
  description="Find implementation patterns",
  prompt="Search for similar feature implementations showing task breakdown, file organization, and git workflow patterns"
)
```
**Benefits**: Learn from successful task decompositions, avoid common pitfalls, reuse proven patterns

**Pro tip:** Use Task tool to find examples, Zen to optimize boundaries, Memory to store successful patterns!

## Goal

To guide an AI assistant in analyzing feature brief and technical approach to define deliverables and decompose them into work units. Focus on outcomes rather than activities, ensuring each deliverable demonstrates measurable progress.

## Process

1. **Assess Feature Complexity:** Determine appropriate task granularity
   - **[ADAPT]:** Simple features = fewer, larger deliverables; Complex = more granular
   - 🧩 **Memory Action:** `memory_read` with `operation="find_similar"` for task sizing patterns

2. **Read Context Documents:** Load feature brief and technical approach from previous phases
   - 🧩 **Memory Action:** `memory_search` to retrieve all related feature decisions and context
   - **[OPTIMIZE]:** Extract effort estimates to guide task sizing

3. **Define Deliverables:** Identify tangible outputs that demonstrate feature completion
   - 🔄 **Sequential Thinking:** Feature goals → user-visible outcomes → technical deliverables
   - **[FLEX]:** Allow 2-8 hour deliverables based on complexity

4. **Hierarchical Decomposition:** Break deliverables into implementation tasks
   - **Level 1:** Feature deliverables (user-visible outcomes)
   - **Level 2:** Technical components (APIs, UI, data)
   - **Level 3:** Work units (if needed for complex deliverables)
   - 🧩 **Memory Action:** `memory_store_decision` for decomposition rationale

5. **Optional User Review:** Present deliverable structure for feedback:
   - "I've defined [X] deliverables for this feature. Would you like to review the breakdown?"
   - **[ADAPT]:** Skip for simple features, require for complex
   - If user reviews, WAIT for feedback

6. **Generate Implementation Plan:** Create detailed specifications with git workflow
   - **[OPTIMIZE]:** Include pattern references from similar past features
   - 🧩 **Memory Action:** `memory_create_thread` linking all planning artifacts

## Feature Task Principles

### Deliverable-Focused Planning
Each deliverable MUST:
- **Demonstrate Value:** Show measurable progress toward feature completion
- **Be Testable:** Have clear acceptance criteria from the feature brief
- **Stand Alone:** Function independently or with minimal dependencies
- **Size Appropriately:** Match complexity (2-8 hours based on feature complexity)

### Hierarchical Task Structure
```
Feature
├── Deliverable 1: User Authentication Flow
│   ├── Task 1.1: API endpoints (4h)
│   ├── Task 1.2: UI components (3h)
│   └── Task 1.3: Integration tests (2h)
├── Deliverable 2: Data Persistence
│   ├── Task 2.1: Database schema (2h)
│   └── Task 2.2: Repository layer (4h)
└── Deliverable 3: User Notifications
    └── Task 3.1: Complete notification system (6h)
```

### [FLEX] Adaptive Sizing
- **Simple Features:** 1-2 deliverables, 4-8 hours each
- **Medium Features:** 3-4 deliverables, 2-6 hours each
- **Complex Features:** 5+ deliverables with sub-tasks

### Validation Checklist
Before finalizing each deliverable:
- [ ] **Clear Outcome:** What will exist after completion
- [ ] **Success Criteria:** How to verify it works
- [ ] **Integration Points:** How it connects to existing system
- [ ] **Pattern Reuse:** Similar implementations to reference
- [ ] **Git Strategy:** Branch and PR approach

## Feature Task Structure

Each generated feature task should include these sections:

### 1. Feature Task Overview
- **Task ID:** FT-[feature-id]-[number] (e.g., FT-001-001, FT-001-002)
- **Task Name:** Clear, comprehensive name (e.g., "Implement Complete Task Priority Management System")
- **Parent Feature:** Reference to feature (e.g., "Feature: Task Priority Management")
- **Estimated Duration:** ~6 hours (full day for senior engineer)
- **Implementation Type:** Full Stack (combines Backend, Frontend, Tests, Documentation)
- **Integration Points:** All existing components this comprehensive task touches

### 🔀 Git Workflow (REQUIRED)
**BEFORE STARTING:**
```bash
git checkout -b feature/FT-[feature-id]-[num]-[short-desc]
# Example: git checkout -b feature/FT-001-001-priority-field
```

**AFTER COMPLETING:**
```bash
git add .
git commit -m "feat(FT-[feature-id]-[num]): [brief description]

Implemented:
- [what was built]

Integration:
- [how it connects with existing system]

Notes:
- [implementation details and decisions]"

git push -u origin feature/FT-[feature-id]-[num]-[short-desc]
```

### 2. Integration Specification
- **Existing Components:** Specific files/components this task modifies or extends
- **New Components:** New files/components this task creates
- **File Size Guidelines:** 
  - **Target:** <300 lines per file for optimal LLM processing
  - **Maximum:** 500 lines per file (hard limit)
  - **Split Strategy:** If approaching 500 lines, break into logical modules
- **API Integration:** How task integrates with existing APIs
- **Data Integration:** How task works with existing data models
- **UI Integration:** How task fits into existing user interface

### 3. Implementation Details
- **Step-by-Step Approach:** Numbered implementation steps within existing codebase
- **Code Examples:** Key code snippets showing integration patterns
- **Existing Code Modifications:** Specific changes to existing files
- **New Code Creation:** New files and their structure
- **Dependencies:** Libraries or components needed

### 4. Acceptance Criteria
- **Functional Criteria:** What the task must accomplish
- **Integration Criteria:** How it must work with existing system
- **Performance Criteria:** Performance requirements within existing system
- **Quality Criteria:** Code quality and consistency requirements

### 5. Testing Requirements
- **Unit Tests:** Specific test cases for new functionality
  - **Go Projects:** Test files must be alongside implementation (e.g., `feature.go` → `feature_test.go`)
  - **Test Package:** Use same package for white-box testing or `_test` suffix for black-box
- **Integration Tests:** Tests for interaction with existing components
- **Manual Testing:** Manual validation steps
- **Regression Testing:** Ensuring existing functionality still works

### 6. Definition of Done
- **Code Complete:** All code written and integrated
- **Tests Passing:** All tests written and passing
- **Quality Checks Pass:** All language-specific quality validation complete
- **Integration Verified:** Works seamlessly with existing system
- **Performance Validated:** Meets performance requirements
- **Git Workflow Complete:** Branch created, committed, and PR submitted
- **🧩 Memory Actions Complete:** Implementation progress stored

### 7. Quality Assurance Requirements
**CRITICAL:** Each feature task MUST include programming language-specific quality checks:

#### Go Projects
```bash
# Run after each feature task completion
make fmt              # Code formatting
make vet              # Static analysis
gosec ./...          # Security analysis
govulncheck ./...    # Vulnerability check
perfsprint ./...     # Performance analysis
make lint            # Comprehensive linting
go test ./...        # Test execution

# After quality checks pass, build to ensure compilation
go build ./...       # Build verification
```

#### TypeScript/JavaScript Projects
```bash
# Run after each feature task completion
npm run lint         # ESLint code quality
npm run typecheck    # TypeScript validation
npm test            # Test execution
npm run build       # Production build verification
```

#### Python Projects
```bash
# Run after each feature task completion
ruff check .         # Linting and formatting
mypy .              # Type checking
pytest              # Test execution
black .             # Code formatting
```

#### Other Languages
- **Rust:** `cargo fmt && cargo clippy && cargo test`
- **Java:** `mvn compile && mvn test && mvn checkstyle:check`
- **C#:** `dotnet format && dotnet test && dotnet build`

**FAILURE PROTOCOL:** If quality checks fail:
1. Fix issues immediately before proceeding
2. Document quality violations in memory: `memory_store_chunk` with tag `quality-violation`
3. Re-run checks to ensure resolution
4. Only mark feature task as complete when ALL quality checks pass

### 🚨 Pre-Emptive Quality Guidance (CRITICAL)

**IMPORTANT:** Use these patterns to avoid common quality check failures in feature implementation:

#### Go Language Anti-Patterns to Avoid in Features
**Error Handling:**
```go
// ❌ WRONG - causes errcheck/staticcheck violations
fmt.Errorf("feature not available")  // For static messages

// ✅ CORRECT - use errors.New for static messages
errors.New("feature not available")

// ✅ CORRECT - use fmt.Errorf only with variables
fmt.Errorf("feature %s not available", featureName)
```

**Feature Integration Patterns:**
```go
// ❌ WRONG - causes high complexity in feature integration
func IntegrateFeature(feature Feature, system System) error {
    if feature.Enabled {
        if system.Ready {
            if feature.Config != nil {
                if len(feature.Config.Dependencies) > 0 {
                    // Deep nesting in feature integration
                }
            }
        }
    }
    return nil
}

// ✅ CORRECT - clean feature integration
func IntegrateFeature(feature Feature, system System) error {
    if !feature.Enabled {
        return nil  // Early return for disabled features
    }
    if !system.Ready {
        return errors.New("system not ready for feature integration")
    }
    if feature.Config == nil {
        return errors.New("feature configuration required")
    }
    if len(feature.Config.Dependencies) == 0 {
        return nil  // No dependencies to process
    }
    
    // Clean integration logic
    return system.IntegrateFeature(feature)
}
```

**String Operations in Feature Code:**
```go
// ❌ WRONG - causes perfsprint violations
featureID := fmt.Sprintf("%d", feature.ID)        // Use strconv.Itoa
featureName := fmt.Sprintf("%s", feature.Name)    // Direct string conversion
featureKey := fmt.Sprintf("feature_%s", name)     // Use concatenation

// ✅ CORRECT - performance optimized feature code
featureID := strconv.Itoa(feature.ID)             // Efficient integer conversion
featureName := feature.Name                       // Direct assignment
featureKey := "feature_" + name                   // Simple concatenation
```

**Feature Data Processing:**
```go
// ❌ WRONG - causes prealloc violations
var featureData []FeatureData
for _, item := range featureItems {
    featureData = append(featureData, processItem(item))
}

// ✅ CORRECT - pre-allocate for feature data
featureData := make([]FeatureData, 0, len(featureItems))
for _, item := range featureItems {
    featureData = append(featureData, processItem(item))
}
```

#### TypeScript/JavaScript Feature Patterns
```typescript
// ❌ WRONG - common feature implementation issues
const processFeature = (data: any) => {           // Avoid 'any' in features
    let result = data.process();                  // Use const when possible
    if (result == null) return null;              // Use strict equality
}

// ✅ CORRECT - type-safe feature implementation
interface FeatureData {
    id: string;
    config: FeatureConfig;
    process(): FeatureResult | null;
}

const processFeature = (data: FeatureData): FeatureResult | null => {
    const result = data.process();                // const for immutable
    if (result === null) return null;             // Strict equality
    return result;
}
```

#### Python Feature Patterns
```python
# ❌ WRONG - common feature violations
def process_feature(data):                        # Missing type hints
    if hasattr(data, 'process'):                  # Unsafe attribute check
        return data.process()

# ✅ CORRECT - type-safe feature patterns
from typing import Protocol, Optional

class FeatureData(Protocol):
    def process(self) -> Optional[str]: ...

def process_feature(data: FeatureData) -> Optional[str]:
    return data.process()
```

### 🎯 Feature-Specific Quality Strategies

**Keep Feature Functions Focused:**
- **Target:** <25 lines per feature function
- **Maximum:** 40 lines (split if larger)
- **Strategy:** One feature responsibility per function

**Feature Error Handling:**
```go
// ✅ RECOMMENDED pattern for feature error handling
func ExecuteFeatureWithValidation(input FeatureInput) (*FeatureResult, error) {
    // Validate feature prerequisites
    if err := input.ValidateFeatureRequirements(); err != nil {
        return nil, fmt.Errorf("feature requirements not met: %w", err)
    }
    
    // Execute feature with proper error wrapping
    result, err := input.ExecuteFeature()
    if err != nil {
        return nil, fmt.Errorf("feature execution failed: %w", err)
    }
    
    // Validate feature integration
    if err := result.ValidateIntegration(); err != nil {
        return nil, fmt.Errorf("feature integration validation failed: %w", err)
    }
    
    return result, nil
}
```

**Avoid Common Feature Anti-Patterns:**
```go
// ❌ WRONG - complex feature processing
func ProcessFeatureList(features []Feature) error {
    for i := 0; i < len(features); i++ {          // Use range instead
        if features[i].Type == "critical" {
            if features[i].Dependencies != nil {
                if len(features[i].Dependencies) > 0 {
                    // Deep nesting in feature processing
                }
            }
        }
    }
    return nil
}

// ✅ CORRECT - clean feature processing
func ProcessFeatureList(features []Feature) error {
    for _, feature := range features {            // Clean iteration
        if err := processIndividualFeature(feature); err != nil {
            return fmt.Errorf("feature %s processing failed: %w", feature.ID, err)
        }
    }
    return nil
}

func processIndividualFeature(feature Feature) error {
    if feature.Type != "critical" {
        return nil  // Early return for non-critical features
    }
    if feature.Dependencies == nil || len(feature.Dependencies) == 0 {
        return nil  // Guard clause prevents nesting
    }
    
    // Process critical feature with dependencies
    return feature.ProcessWithDependencies()
}
```

### 📏 Feature File Size Guidelines

**Optimal Feature File Sizes:**
- **Go feature files:** <250 lines target, 400 lines maximum
- **TypeScript feature files:** <200 lines target, 350 lines maximum
- **Python feature files:** <150 lines target, 250 lines maximum

**Feature Decomposition Strategy:**
1. **Separate by concern** - Feature logic, integration, validation in different files
2. **Extract utilities** - Common feature operations in utility modules
3. **Interface-driven** - Clear contracts between feature components
4. **Testable units** - Each feature component easily testable

### 🔍 Feature Pre-Implementation Quality Checklist

Before implementing any feature task, ensure specification includes:
- [ ] **Integration points** - Clear connection with existing system
- [ ] **Backward compatibility** - Existing functionality preserved
- [ ] **Error propagation** - Proper error handling and reporting
- [ ] **Performance impact** - Feature doesn't degrade system performance
- [ ] **Testing strategy** - Unit and integration tests for feature
- [ ] **Configuration management** - Feature flags and settings handled properly
- [ ] **Security considerations** - Feature doesn't introduce vulnerabilities
- [ ] **Type safety** - Strong typing throughout feature implementation

### 🔄 Quality-First Feature Implementation Flow

**For each feature task implementation:**
1. **Design integration first** - Define how feature connects with existing system
2. **Write integration tests** - Test feature works with existing components
3. **Implement with quality patterns** - Use proven patterns from the start
4. **Test backward compatibility** - Ensure existing features still work
5. **Validate performance** - Feature doesn't impact system performance

**Feature Implementation Template:**
```go
// ✅ RECOMMENDED feature implementation template
package feature

import (
    "context"
    "errors"
    "fmt"
)

// FeatureInput defines the input contract for this feature
type FeatureInput struct {
    ID               string            `json:"id" validate:"required"`
    Config           FeatureConfig     `json:"config" validate:"required"`
    ExistingSystem   SystemInterface   `json:"-"`
    Dependencies     []string          `json:"dependencies"`
}

// FeatureResult defines the output contract for this feature
type FeatureResult struct {
    ID               string            `json:"id"`
    Status           string            `json:"status"`
    IntegrationData  map[string]any    `json:"integration_data"`
    Errors           []string          `json:"errors,omitempty"`
}

// Execute implements the feature with proper integration
func (input *FeatureInput) Execute(ctx context.Context) (*FeatureResult, error) {
    // Validate feature can be integrated
    if err := input.ValidateIntegration(); err != nil {
        return nil, fmt.Errorf("integration validation failed: %w", err)
    }
    
    // Check context cancellation
    select {
    case <-ctx.Done():
        return nil, ctx.Err()
    default:
    }
    
    // Initialize feature result
    result := &FeatureResult{
        ID:              input.ID,
        Status:          "integrating",
        IntegrationData: make(map[string]any),
    }
    
    // Execute feature integration
    if err := input.integrateWithSystem(result); err != nil {
        return nil, fmt.Errorf("system integration failed: %w", err)
    }
    
    result.Status = "integrated"
    return result, nil
}

// ValidateIntegration ensures feature can be safely integrated
func (input *FeatureInput) ValidateIntegration() error {
    if input.ID == "" {
        return errors.New("feature ID is required")
    }
    if input.ExistingSystem == nil {
        return errors.New("existing system reference is required")
    }
    if !input.ExistingSystem.CanIntegrateFeature(input.ID) {
        return errors.New("system cannot integrate this feature")
    }
    return nil
}

// integrateWithSystem handles the core feature integration logic
func (input *FeatureInput) integrateWithSystem(result *FeatureResult) error {
    // Implementation specific to this feature
    // Keep this function focused on integration
    return input.ExistingSystem.IntegrateFeature(input.Config)
}
```

### 🧠 Required Memory Actions During Implementation
**CRITICAL:** Every feature task implementation MUST include these Memory MCP actions:

**Before Starting:**
```
memory_store_chunk
  content="Starting FT-[ID]: [task-name]. Integration context: [existing components involved]"
  tags=["feature-task", "started", "FT-[ID]", "feature-name"]
  session_id="[current-session]"
  repository="[project-repo]"
```

**During Implementation:**
```
memory_store_decision 
  decision="[key integration or implementation choice]"
  rationale="[why this approach works with existing system]"
  alternatives="[other options considered]"
  session_id="[current-session]"
  repository="[project-repo]"
```

**After Completion:**
```
memory_store_chunk
  content="Completed FT-[ID]: [summary]. Integration success: [how it works with existing system]. Learnings: [insights for future features]"
  tags=["feature-task", "completed", "FT-[ID]", "integration-success"]
  session_id="[current-session]"
  repository="[project-repo]"
```

### 🔄 Sequential Thinking for Complex Tasks
**RECOMMENDED:** For complex integration decisions, use Sequential Thinking MCP:
```
mcp__sequential-thinking__sequentialthinking
  thought="[integration challenge or implementation decision]"
  thought_number=1
  total_thoughts=3-5
  next_thought_needed=true
```
Use when facing:
- Complex integration with existing components
- Performance optimization within existing system
- API design that affects existing endpoints
- Data model changes that impact existing features

### 7. Dependencies and Integration
- **Required Tasks:** Feature tasks that must be completed first
- **Existing Component Dependencies:** Current system components needed
- **External Dependencies:** Third-party services or libraries
- **Integration Sequence:** Order for integrating with existing system

## Implementation Plan Structure

Create organized implementation plan:

```
docs/pre-development/tasks/feature-[feature-name]/
├── overview.md                           # Feature implementation overview
├── FT-[feature-id]-001-[task-name].md    # Individual feature tasks
├── FT-[feature-id]-002-[task-name].md
├── FT-[feature-id]-003-[task-name].md
└── implementation-sequence.md             # Task execution order and dependencies
```

### Overview Document Structure

```markdown
# Feature Implementation Plan: [Feature Name]

## 🎯 Implementation Overview

**Feature:** [Feature name]
**Total Tasks:** [Number of implementation tasks]
**Estimated Duration:** [Total development time]
**Integration Complexity:** [Low/Medium/High]

## 📋 Task Summary

| Task ID | Name | Duration | Type | Dependencies |
|---------|------|----------|------|--------------|
| FT-001-001 | [Task name] | 3h | Code | None |
| FT-001-002 | [Task name] | 2h | Integration | FT-001-001 |
| FT-001-003 | [Task name] | 4h | Testing | FT-001-002 |

## 🔗 Integration Map

```mermaid
graph TD
    A[Existing Component 1] -->|Modified by| B[FT-001-001]
    B -->|Enables| C[FT-001-002]
    C -->|Integrates with| D[Existing Component 2]
    C -->|Tested by| E[FT-001-003]
```

## 📅 Implementation Sequence

### Week 1
- **Day 1:** FT-001-001 - [Task name]
- **Day 2:** FT-001-002 - [Task name]
- **Day 3:** FT-001-003 - [Task name]

### Parallel Opportunities
- [Tasks that can be done simultaneously]

### Critical Path
- [Tasks that block other work]
```

## Example Feature Task

```markdown
## FT-001-001: Implement Complete Task Priority Management System

### 1. Feature Task Overview
- **Task ID:** FT-001-001
- **Task Name:** Implement Complete Task Priority Management System
- **Parent Feature:** Task Priority Management
- **Estimated Duration:** ~6 hours (full day for senior engineer)
- **Implementation Type:** Full Stack (Model, API, UI, Tests, Migration)
- **Integration Points:** Task model, Task API, Task UI components, Database schema, Test suites

### 🔀 Git Workflow (REQUIRED)
**BEFORE STARTING:**
```bash
git checkout -b feature/FT-001-001-priority-field
```

**AFTER COMPLETING:**
```bash
git add .
git commit -m "feat(FT-001-001): implement complete task priority management system

Implemented:
- Added priority enum to task model with full validation
- Created database migration for priority field
- Extended task API endpoints for priority operations
- Added priority filter/sort to task list UI
- Implemented priority badge component
- Created comprehensive test suite

Integration:
- Maintains backward compatibility with existing tasks
- Default priority set to 'medium' for existing tasks
- UI gracefully handles tasks without priority
- API supports both old and new task formats

Tests:
- Unit tests for model validation
- API integration tests for all endpoints
- UI component tests with RTL
- E2E tests for priority workflows

Notes:
- Used existing validation patterns
- Followed established architecture
- Performance optimized for large task lists"

git push -u origin feature/FT-001-001-priority-management
```

### 2. Integration Specification
- **Existing Components:** 
  - `models/task.js` - Extend with priority field and validation
  - `routes/tasks.js` - Update all CRUD endpoints for priority
  - `controllers/taskController.js` - Add priority filtering, sorting, validation
  - `components/TaskList.jsx` - Add priority display and filtering
  - `components/TaskForm.jsx` - Add priority selection
  - `services/taskService.js` - Update service layer for priority logic
- **New Components:** 
  - `migrations/add_task_priority.sql` - Database migration
  - `components/PriorityBadge.jsx` - Reusable priority display component
  - `utils/priorityHelpers.js` - Priority utility functions
  - `tests/priority.test.js` - Comprehensive test suite
- **File Size Guidelines:** All files stay under 300 lines through modular design
- **API Integration:** 
  - GET /tasks - Add priority filter and sort parameters
  - POST /tasks - Accept priority in request body
  - PUT /tasks/:id - Allow priority updates
  - GET /tasks/priorities - New endpoint for priority options
- **Data Integration:** 
  - Add priority column with migration
  - Update all queries to include priority
  - Add indexes for priority-based queries
- **UI Integration:**
  - Task list shows color-coded priority badges
  - Filter dropdown includes priority options
  - Sort options include priority ordering

### 3. Implementation Details
**Step-by-Step Approach:**
1. **Backend Implementation (2 hours):**
   - Create and run database migration for priority field
   - Update Task model with priority enum and validation
   - Extend TaskService with priority business logic
   - Update TaskController for all CRUD operations
   - Modify API routes with new parameters
   - Add comprehensive backend tests

2. **Frontend Implementation (2 hours):**
   - Create PriorityBadge component with styling
   - Update TaskList to display and filter by priority
   - Enhance TaskForm with priority selector
   - Add priority to task service layer
   - Implement sorting by priority
   - Add frontend component tests

3. **Integration & Testing (1.5 hours):**
   - Write integration tests for API endpoints
   - Create E2E tests for priority workflows
   - Test migration rollback scenarios
   - Verify backward compatibility
   - Performance test with large datasets

4. **Documentation & Polish (0.5 hours):**
   - Update API documentation
   - Add JSDoc comments
   - Update README with priority feature
   - Create migration guide for existing data

**Code Examples:**
```javascript
// Task model extension (models/task.js)
const TaskPriority = {
  LOW: 'low',
  MEDIUM: 'medium', 
  HIGH: 'high'
};

// Add to existing Task schema
priority: {
  type: String,
  enum: Object.values(TaskPriority),
  default: TaskPriority.MEDIUM
}
```

**Database Migration:**
```sql
-- migrations/add_task_priority.sql
ALTER TABLE tasks 
ADD COLUMN priority VARCHAR(10) 
DEFAULT 'medium' 
CHECK (priority IN ('low', 'medium', 'high'));
```

### 4. Acceptance Criteria
- **Functional Criteria:**
  - Complete priority system works end-to-end (model → API → UI)
  - Users can create tasks with priority
  - Users can update task priority
  - Users can filter tasks by priority
  - Users can sort tasks by priority
  - Default priority applied to existing tasks
  
- **Integration Criteria:**
  - All existing functionality remains intact
  - Backward compatibility maintained
  - No breaking changes to API contracts
  - UI gracefully handles legacy data
  - All existing tests continue to pass
  
- **Performance Criteria:**
  - Task list loads in <200ms with 1000+ tasks
  - Priority filtering/sorting adds <50ms overhead
  - Database queries use proper indexes
  - No memory leaks in UI components
  
- **Quality Criteria:**
  - >90% test coverage for new code
  - All quality checks pass (lint, type, security)
  - Code follows established patterns
  - Comprehensive error handling

### 5. Testing Requirements
- **Backend Unit Tests:**
  - Task model validation for all priority values
  - Service layer business logic for priority
  - Controller handling of priority operations
  - Migration rollback scenarios
  - Error handling for invalid priorities
  
- **Frontend Unit Tests:**
  - PriorityBadge component rendering
  - TaskList filtering by priority
  - TaskForm priority selection
  - Priority sorting logic
  - Accessibility of priority features
  
- **Integration Tests:**
  - Full API CRUD operations with priority
  - Database migration and rollback
  - Concurrent priority updates
  - Large dataset performance
  - Legacy data compatibility
  
- **E2E Tests:**
  - Complete user workflow for priority management
  - Filter and sort combinations
  - Priority updates reflect immediately
  - Keyboard navigation for priority features
  - Mobile responsiveness of priority UI
  
- **Performance Tests:**
  - Load test with 10,000+ tasks
  - Concurrent user operations
  - Memory usage profiling
  - Query optimization validation

### 6. Definition of Done
- [ ] Complete backend implementation with model, service, controller
- [ ] Database migration applied and tested
- [ ] All API endpoints support priority operations
- [ ] Frontend components implemented and styled
- [ ] Filter and sort functionality working
- [ ] All unit tests passing (>90% coverage)
- [ ] Integration tests validating full stack
- [ ] E2E tests confirming user workflows
- [ ] Performance benchmarks met
- [ ] Accessibility standards met (WCAG 2.1 AA)
- [ ] API documentation updated
- [ ] Code passes all quality checks
- [ ] Git workflow completed with comprehensive commit
- [ ] PR created and ready for review
- [ ] 🧩 Memory actions completed

### 7. Dependencies and Integration
- **Required Tasks:** None (foundational task)
- **Existing Component Dependencies:** Task model, Task API, Database
- **External Dependencies:** Database migration tool
- **Integration Sequence:** This task enables all subsequent priority-related tasks
```

## Memory Actions During Process

### Initial Context Retrieval
```
memory_search "feature-brief technical-approach [feature-name]" repository="[project-repo]"
memory_store_chunk
  content="Starting implementation plan for [feature-name]. Context: [brief and approach summary]"
  tags=["implementation-plan", "started", "feature-name"]
  session_id="[current-session]"
  repository="[project-repo]"
```

### After Task Generation
```
memory_store_decision
  decision="Task breakdown for [feature-name]"
  rationale="Integration approach: [approach]. Task boundaries: [reasoning]. Implementation sequence: [sequence logic]"
  context="Total tasks: [count]. Critical path: [tasks]. Parallel opportunities: [tasks]"
  session_id="[current-session]"
  repository="[project-repo]"
```

### After Plan Completion
```
memory_create_thread
  name="Feature Implementation: [feature-name]"
  description="Complete feature development from brief through implementation tasks"
  chunk_ids=["[feature-brief-chunks]", "[tech-approach-chunks]", "[implementation-plan-chunks]"]
  repository="[project-repo]"
```

## Quality Validation

Before finalizing implementation plan, ensure:

### Task Atomicity
- [ ] **Each task is completable in 2-4 hours**
- [ ] **Clear deliverable for each task**
- [ ] **Tasks are independent where possible**
- [ ] **Dependencies are minimal and clear**

### Integration Quality
- [ ] **All integration points identified**
- [ ] **Existing system impact minimized**
- [ ] **File size limits respected**
- [ ] **Performance impact considered**

### Implementation Readiness
- [ ] **Clear implementation path for each task**
- [ ] **All dependencies available**
- [ ] **Testing approach defined**
- [ ] **Git workflow included**

## Final Instructions

1. **Integration First** - Always prioritize clean integration with existing system
2. **Atomic Focus** - Ensure tasks are truly atomic and implementable
3. **Memory Integration** - Store all decisions and patterns for future features
4. **Quality Consistency** - Maintain existing code quality and patterns
5. **Git Discipline** - Include complete git workflow for every task
6. **Performance Aware** - Consider impact on existing system performance

## Relationship to Feature Development Chain

This implementation plan is part of the streamlined feature workflow:

1. **feature-brief.mdc** → Captures feature requirements
2. **technical-approach.mdc** → Defines implementation strategy
3. **implementation-plan.mdc** → Creates atomic tasks ← **YOU ARE HERE**
4. **test-strategy.mdc** → Defines feature test coverage

## Next Steps

After completing the implementation plan:
1. **Proceed to Test Strategy:** Run `4-test-strategy.mdc` to define focused test coverage
2. **Begin Implementation:** Start with the first atomic task
3. **Track Progress:** Use the task breakdown for sprint planning

This implementation plan provides the final level of detail needed for efficient feature development with seamless integration into existing systems.