---
description: Convert feature brief and technical approach into atomic implementation tasks
globs: 
alwaysApply: false
---
# Rule: Creating Feature Implementation Plan

## 🧠 Enhanced Analysis Tools - USE THESE!

**CRITICAL:** Leverage these tools throughout the implementation planning process:

### 🧩 Memory MCP Integration
- **Retrieve context:** `memory_search` for feature brief, technical approach, and related decisions
- **Store task logic:** `memory_store_decision` for task breakdown rationale and implementation sequencing
- **Reference implementations:** `memory_search` for similar feature implementations and successful patterns
- **Track progress:** `memory_tasks` for implementation planning workflow
- **Store patterns:** `memory_store_chunk` with successful task structures for future features
- **Tags to use:** `["implementation-plan", "feature-tasks", "breakdown", "feature-name", "development"]`

### 🔄 Sequential Thinking MCP
- **Use for:** Complex task decomposition, dependency analysis, implementation sequencing
- **Pattern:** Technical approach → implementation components → task boundaries → git workflow
- **Benefit:** Ensures tasks are atomic, properly sequenced, and efficiently implementable
- **When:** During task boundary analysis and dependency mapping

**Pro tip:** Store every task breakdown decision to improve future feature task generation!

## Goal

To guide an AI assistant in analyzing feature brief and technical approach to generate atomic, implementable tasks with integrated git workflow. Each task must be specific, actionable, and completable in a single development session.

## Process

1. **Read Context Documents:** Load feature brief and technical approach from previous phases
   - 🧩 **Memory Action:** `memory_search` to retrieve all related feature decisions and context
   - 🧩 **Memory Action:** `memory_tasks` to track implementation planning workflow with session_id

2. **Analyze Implementation Scope:** Extract implementation requirements and integration points
   - 🔄 **Sequential Thinking:** Map technical approach to implementation components and dependencies

3. **Apply Atomic Principles:** Ensure each task is self-contained and implementable in 2-4 hours
   - 🔄 **Sequential Thinking:** Validate task boundaries and completion criteria

4. **Generate Implementation Tasks:** Create detailed task specifications with git workflow
   - 🧩 **Memory Action:** `memory_store_decision` for task breakdown and implementation approach

5. **Optional User Review:** Since tasks are implementation details, user review is optional:
   - "I've created detailed implementation tasks. Would you like to review the breakdown, or shall I proceed with saving them?"
   - If user wants to review, WAIT for feedback
   - If user approves or skips review, proceed to save
   - 🧩 **Memory Action:** `memory_store_chunk` with user feedback (if provided)

6. **Save Implementation Plan:** Create organized task files in `/docs/pre-development/tasks/feature-[feature-name]/`
   - 🧩 **Memory Action:** `memory_create_thread` completing feature brief → technical approach → implementation plan

## Feature Task Principles

### Definition of "Atomic Feature Task"
Each task MUST be:
- **Single Session:** Completable in 2-4 hours maximum
- **Specific:** Clear implementation requirements within existing system
- **Testable:** Can be validated independently
- **Integrable:** Fits cleanly with existing codebase
- **Git-Ready:** Includes complete git workflow

### Task Validation Checklist
Before finalizing each task, ensure:
- [ ] **Clear Deliverable:** Specific code, API, or UI component
- [ ] **Integration Path:** Clear how it connects with existing system
- [ ] **Test Strategy:** Clear validation approach
- [ ] **File Size Compliance:** Targets <300 lines, max 500 lines per file
- [ ] **Git Workflow:** Complete branch/commit/PR process

## Feature Task Structure

Each generated feature task should include these sections:

### 1. Feature Task Overview
- **Task ID:** FT-[feature-id]-[number] (e.g., FT-001-001, FT-001-002)
- **Task Name:** Clear, action-oriented name (e.g., "Add Priority Field to Task Model")
- **Parent Feature:** Reference to feature (e.g., "Feature: Task Priority Management")
- **Estimated Duration:** 2-4 hours maximum
- **Implementation Type:** Code, Configuration, Testing, Integration
- **Integration Points:** Existing components this task touches

### 🔀 Git Workflow (REQUIRED)
**BEFORE STARTING:**
```bash
git checkout -b feature/FT-[feature-id]-[num]-[short-desc]
# Example: git checkout -b feature/FT-001-001-priority-field
```

**AFTER COMPLETING:**
```bash
git add .
git commit -m "feat(FT-[feature-id]-[num]): [brief description]

Implemented:
- [what was built]

Integration:
- [how it connects with existing system]

Notes:
- [implementation details and decisions]"

git push -u origin feature/FT-[feature-id]-[num]-[short-desc]
```

### 2. Integration Specification
- **Existing Components:** Specific files/components this task modifies or extends
- **New Components:** New files/components this task creates
- **File Size Guidelines:** 
  - **Target:** <300 lines per file for optimal LLM processing
  - **Maximum:** 500 lines per file (hard limit)
  - **Split Strategy:** If approaching 500 lines, break into logical modules
- **API Integration:** How task integrates with existing APIs
- **Data Integration:** How task works with existing data models
- **UI Integration:** How task fits into existing user interface

### 3. Implementation Details
- **Step-by-Step Approach:** Numbered implementation steps within existing codebase
- **Code Examples:** Key code snippets showing integration patterns
- **Existing Code Modifications:** Specific changes to existing files
- **New Code Creation:** New files and their structure
- **Dependencies:** Libraries or components needed

### 4. Acceptance Criteria
- **Functional Criteria:** What the task must accomplish
- **Integration Criteria:** How it must work with existing system
- **Performance Criteria:** Performance requirements within existing system
- **Quality Criteria:** Code quality and consistency requirements

### 5. Testing Requirements
- **Unit Tests:** Specific test cases for new functionality
  - **Go Projects:** Test files must be alongside implementation (e.g., `feature.go` → `feature_test.go`)
  - **Test Package:** Use same package for white-box testing or `_test` suffix for black-box
- **Integration Tests:** Tests for interaction with existing components
- **Manual Testing:** Manual validation steps
- **Regression Testing:** Ensuring existing functionality still works

### 6. Definition of Done
- **Code Complete:** All code written and integrated
- **Tests Passing:** All tests written and passing
- **Quality Checks Pass:** All language-specific quality validation complete
- **Integration Verified:** Works seamlessly with existing system
- **Performance Validated:** Meets performance requirements
- **Git Workflow Complete:** Branch created, committed, and PR submitted
- **🧩 Memory Actions Complete:** Implementation progress stored

### 7. Quality Assurance Requirements
**CRITICAL:** Each feature task MUST include programming language-specific quality checks:

#### Go Projects
```bash
# Run after each feature task completion
make fmt              # Code formatting
make vet              # Static analysis
gosec ./...          # Security analysis
govulncheck ./...    # Vulnerability check
perfsprint ./...     # Performance analysis
make lint            # Comprehensive linting
go test ./...        # Test execution

# After quality checks pass, build to ensure compilation
go build ./...       # Build verification
```

#### TypeScript/JavaScript Projects
```bash
# Run after each feature task completion
npm run lint         # ESLint code quality
npm run typecheck    # TypeScript validation
npm test            # Test execution
npm run build       # Production build verification
```

#### Python Projects
```bash
# Run after each feature task completion
ruff check .         # Linting and formatting
mypy .              # Type checking
pytest              # Test execution
black .             # Code formatting
```

#### Other Languages
- **Rust:** `cargo fmt && cargo clippy && cargo test`
- **Java:** `mvn compile && mvn test && mvn checkstyle:check`
- **C#:** `dotnet format && dotnet test && dotnet build`

**FAILURE PROTOCOL:** If quality checks fail:
1. Fix issues immediately before proceeding
2. Document quality violations in memory: `memory_store_chunk` with tag `quality-violation`
3. Re-run checks to ensure resolution
4. Only mark feature task as complete when ALL quality checks pass

### 🚨 Pre-Emptive Quality Guidance (CRITICAL)

**IMPORTANT:** Use these patterns to avoid common quality check failures in feature implementation:

#### Go Language Anti-Patterns to Avoid in Features
**Error Handling:**
```go
// ❌ WRONG - causes errcheck/staticcheck violations
fmt.Errorf("feature not available")  // For static messages

// ✅ CORRECT - use errors.New for static messages
errors.New("feature not available")

// ✅ CORRECT - use fmt.Errorf only with variables
fmt.Errorf("feature %s not available", featureName)
```

**Feature Integration Patterns:**
```go
// ❌ WRONG - causes high complexity in feature integration
func IntegrateFeature(feature Feature, system System) error {
    if feature.Enabled {
        if system.Ready {
            if feature.Config != nil {
                if len(feature.Config.Dependencies) > 0 {
                    // Deep nesting in feature integration
                }
            }
        }
    }
    return nil
}

// ✅ CORRECT - clean feature integration
func IntegrateFeature(feature Feature, system System) error {
    if !feature.Enabled {
        return nil  // Early return for disabled features
    }
    if !system.Ready {
        return errors.New("system not ready for feature integration")
    }
    if feature.Config == nil {
        return errors.New("feature configuration required")
    }
    if len(feature.Config.Dependencies) == 0 {
        return nil  // No dependencies to process
    }
    
    // Clean integration logic
    return system.IntegrateFeature(feature)
}
```

**String Operations in Feature Code:**
```go
// ❌ WRONG - causes perfsprint violations
featureID := fmt.Sprintf("%d", feature.ID)        // Use strconv.Itoa
featureName := fmt.Sprintf("%s", feature.Name)    // Direct string conversion
featureKey := fmt.Sprintf("feature_%s", name)     // Use concatenation

// ✅ CORRECT - performance optimized feature code
featureID := strconv.Itoa(feature.ID)             // Efficient integer conversion
featureName := feature.Name                       // Direct assignment
featureKey := "feature_" + name                   // Simple concatenation
```

**Feature Data Processing:**
```go
// ❌ WRONG - causes prealloc violations
var featureData []FeatureData
for _, item := range featureItems {
    featureData = append(featureData, processItem(item))
}

// ✅ CORRECT - pre-allocate for feature data
featureData := make([]FeatureData, 0, len(featureItems))
for _, item := range featureItems {
    featureData = append(featureData, processItem(item))
}
```

#### TypeScript/JavaScript Feature Patterns
```typescript
// ❌ WRONG - common feature implementation issues
const processFeature = (data: any) => {           // Avoid 'any' in features
    let result = data.process();                  // Use const when possible
    if (result == null) return null;              // Use strict equality
}

// ✅ CORRECT - type-safe feature implementation
interface FeatureData {
    id: string;
    config: FeatureConfig;
    process(): FeatureResult | null;
}

const processFeature = (data: FeatureData): FeatureResult | null => {
    const result = data.process();                // const for immutable
    if (result === null) return null;             // Strict equality
    return result;
}
```

#### Python Feature Patterns
```python
# ❌ WRONG - common feature violations
def process_feature(data):                        # Missing type hints
    if hasattr(data, 'process'):                  # Unsafe attribute check
        return data.process()

# ✅ CORRECT - type-safe feature patterns
from typing import Protocol, Optional

class FeatureData(Protocol):
    def process(self) -> Optional[str]: ...

def process_feature(data: FeatureData) -> Optional[str]:
    return data.process()
```

### 🎯 Feature-Specific Quality Strategies

**Keep Feature Functions Focused:**
- **Target:** <25 lines per feature function
- **Maximum:** 40 lines (split if larger)
- **Strategy:** One feature responsibility per function

**Feature Error Handling:**
```go
// ✅ RECOMMENDED pattern for feature error handling
func ExecuteFeatureWithValidation(input FeatureInput) (*FeatureResult, error) {
    // Validate feature prerequisites
    if err := input.ValidateFeatureRequirements(); err != nil {
        return nil, fmt.Errorf("feature requirements not met: %w", err)
    }
    
    // Execute feature with proper error wrapping
    result, err := input.ExecuteFeature()
    if err != nil {
        return nil, fmt.Errorf("feature execution failed: %w", err)
    }
    
    // Validate feature integration
    if err := result.ValidateIntegration(); err != nil {
        return nil, fmt.Errorf("feature integration validation failed: %w", err)
    }
    
    return result, nil
}
```

**Avoid Common Feature Anti-Patterns:**
```go
// ❌ WRONG - complex feature processing
func ProcessFeatureList(features []Feature) error {
    for i := 0; i < len(features); i++ {          // Use range instead
        if features[i].Type == "critical" {
            if features[i].Dependencies != nil {
                if len(features[i].Dependencies) > 0 {
                    // Deep nesting in feature processing
                }
            }
        }
    }
    return nil
}

// ✅ CORRECT - clean feature processing
func ProcessFeatureList(features []Feature) error {
    for _, feature := range features {            // Clean iteration
        if err := processIndividualFeature(feature); err != nil {
            return fmt.Errorf("feature %s processing failed: %w", feature.ID, err)
        }
    }
    return nil
}

func processIndividualFeature(feature Feature) error {
    if feature.Type != "critical" {
        return nil  // Early return for non-critical features
    }
    if feature.Dependencies == nil || len(feature.Dependencies) == 0 {
        return nil  // Guard clause prevents nesting
    }
    
    // Process critical feature with dependencies
    return feature.ProcessWithDependencies()
}
```

### 📏 Feature File Size Guidelines

**Optimal Feature File Sizes:**
- **Go feature files:** <250 lines target, 400 lines maximum
- **TypeScript feature files:** <200 lines target, 350 lines maximum
- **Python feature files:** <150 lines target, 250 lines maximum

**Feature Decomposition Strategy:**
1. **Separate by concern** - Feature logic, integration, validation in different files
2. **Extract utilities** - Common feature operations in utility modules
3. **Interface-driven** - Clear contracts between feature components
4. **Testable units** - Each feature component easily testable

### 🔍 Feature Pre-Implementation Quality Checklist

Before implementing any feature task, ensure specification includes:
- [ ] **Integration points** - Clear connection with existing system
- [ ] **Backward compatibility** - Existing functionality preserved
- [ ] **Error propagation** - Proper error handling and reporting
- [ ] **Performance impact** - Feature doesn't degrade system performance
- [ ] **Testing strategy** - Unit and integration tests for feature
- [ ] **Configuration management** - Feature flags and settings handled properly
- [ ] **Security considerations** - Feature doesn't introduce vulnerabilities
- [ ] **Type safety** - Strong typing throughout feature implementation

### 🔄 Quality-First Feature Implementation Flow

**For each feature task implementation:**
1. **Design integration first** - Define how feature connects with existing system
2. **Write integration tests** - Test feature works with existing components
3. **Implement with quality patterns** - Use proven patterns from the start
4. **Test backward compatibility** - Ensure existing features still work
5. **Validate performance** - Feature doesn't impact system performance

**Feature Implementation Template:**
```go
// ✅ RECOMMENDED feature implementation template
package feature

import (
    "context"
    "errors"
    "fmt"
)

// FeatureInput defines the input contract for this feature
type FeatureInput struct {
    ID               string            `json:"id" validate:"required"`
    Config           FeatureConfig     `json:"config" validate:"required"`
    ExistingSystem   SystemInterface   `json:"-"`
    Dependencies     []string          `json:"dependencies"`
}

// FeatureResult defines the output contract for this feature
type FeatureResult struct {
    ID               string            `json:"id"`
    Status           string            `json:"status"`
    IntegrationData  map[string]any    `json:"integration_data"`
    Errors           []string          `json:"errors,omitempty"`
}

// Execute implements the feature with proper integration
func (input *FeatureInput) Execute(ctx context.Context) (*FeatureResult, error) {
    // Validate feature can be integrated
    if err := input.ValidateIntegration(); err != nil {
        return nil, fmt.Errorf("integration validation failed: %w", err)
    }
    
    // Check context cancellation
    select {
    case <-ctx.Done():
        return nil, ctx.Err()
    default:
    }
    
    // Initialize feature result
    result := &FeatureResult{
        ID:              input.ID,
        Status:          "integrating",
        IntegrationData: make(map[string]any),
    }
    
    // Execute feature integration
    if err := input.integrateWithSystem(result); err != nil {
        return nil, fmt.Errorf("system integration failed: %w", err)
    }
    
    result.Status = "integrated"
    return result, nil
}

// ValidateIntegration ensures feature can be safely integrated
func (input *FeatureInput) ValidateIntegration() error {
    if input.ID == "" {
        return errors.New("feature ID is required")
    }
    if input.ExistingSystem == nil {
        return errors.New("existing system reference is required")
    }
    if !input.ExistingSystem.CanIntegrateFeature(input.ID) {
        return errors.New("system cannot integrate this feature")
    }
    return nil
}

// integrateWithSystem handles the core feature integration logic
func (input *FeatureInput) integrateWithSystem(result *FeatureResult) error {
    // Implementation specific to this feature
    // Keep this function focused on integration
    return input.ExistingSystem.IntegrateFeature(input.Config)
}
```

### 🧠 Required Memory Actions During Implementation
**CRITICAL:** Every feature task implementation MUST include these Memory MCP actions:

**Before Starting:**
```
memory_store_chunk
  content="Starting FT-[ID]: [task-name]. Integration context: [existing components involved]"
  tags=["feature-task", "started", "FT-[ID]", "feature-name"]
  session_id="[current-session]"
  repository="[project-repo]"
```

**During Implementation:**
```
memory_store_decision 
  decision="[key integration or implementation choice]"
  rationale="[why this approach works with existing system]"
  alternatives="[other options considered]"
  session_id="[current-session]"
  repository="[project-repo]"
```

**After Completion:**
```
memory_store_chunk
  content="Completed FT-[ID]: [summary]. Integration success: [how it works with existing system]. Learnings: [insights for future features]"
  tags=["feature-task", "completed", "FT-[ID]", "integration-success"]
  session_id="[current-session]"
  repository="[project-repo]"
```

### 🔄 Sequential Thinking for Complex Tasks
**RECOMMENDED:** For complex integration decisions, use Sequential Thinking MCP:
```
mcp__sequential-thinking__sequentialthinking
  thought="[integration challenge or implementation decision]"
  thought_number=1
  total_thoughts=3-5
  next_thought_needed=true
```
Use when facing:
- Complex integration with existing components
- Performance optimization within existing system
- API design that affects existing endpoints
- Data model changes that impact existing features

### 7. Dependencies and Integration
- **Required Tasks:** Feature tasks that must be completed first
- **Existing Component Dependencies:** Current system components needed
- **External Dependencies:** Third-party services or libraries
- **Integration Sequence:** Order for integrating with existing system

## Implementation Plan Structure

Create organized implementation plan:

```
docs/pre-development/tasks/feature-[feature-name]/
├── overview.md                           # Feature implementation overview
├── FT-[feature-id]-001-[task-name].md    # Individual feature tasks
├── FT-[feature-id]-002-[task-name].md
├── FT-[feature-id]-003-[task-name].md
└── implementation-sequence.md             # Task execution order and dependencies
```

### Overview Document Structure

```markdown
# Feature Implementation Plan: [Feature Name]

## 🎯 Implementation Overview

**Feature:** [Feature name]
**Total Tasks:** [Number of implementation tasks]
**Estimated Duration:** [Total development time]
**Integration Complexity:** [Low/Medium/High]

## 📋 Task Summary

| Task ID | Name | Duration | Type | Dependencies |
|---------|------|----------|------|--------------|
| FT-001-001 | [Task name] | 3h | Code | None |
| FT-001-002 | [Task name] | 2h | Integration | FT-001-001 |
| FT-001-003 | [Task name] | 4h | Testing | FT-001-002 |

## 🔗 Integration Map

```mermaid
graph TD
    A[Existing Component 1] -->|Modified by| B[FT-001-001]
    B -->|Enables| C[FT-001-002]
    C -->|Integrates with| D[Existing Component 2]
    C -->|Tested by| E[FT-001-003]
```

## 📅 Implementation Sequence

### Week 1
- **Day 1:** FT-001-001 - [Task name]
- **Day 2:** FT-001-002 - [Task name]
- **Day 3:** FT-001-003 - [Task name]

### Parallel Opportunities
- [Tasks that can be done simultaneously]

### Critical Path
- [Tasks that block other work]
```

## Example Feature Task

```markdown
## FT-001-001: Add Priority Field to Task Model

### 1. Feature Task Overview
- **Task ID:** FT-001-001
- **Task Name:** Add Priority Field to Task Model
- **Parent Feature:** Task Priority Management
- **Estimated Duration:** 3 hours
- **Implementation Type:** Code (Backend Model Extension)
- **Integration Points:** Task model, Task API, Task database schema

### 🔀 Git Workflow (REQUIRED)
**BEFORE STARTING:**
```bash
git checkout -b feature/FT-001-001-priority-field
```

**AFTER COMPLETING:**
```bash
git add .
git commit -m "feat(FT-001-001): add priority field to task model

Implemented:
- Added priority enum to task model
- Updated database schema with migration
- Extended task API to handle priority

Integration:
- Maintains backward compatibility with existing tasks
- Default priority set to 'medium' for existing tasks

Notes:
- Used existing validation patterns
- Followed established model structure"

git push -u origin feature/FT-001-001-priority-field
```

### 2. Integration Specification
- **Existing Components:** 
  - `models/task.js` - Extend with priority field
  - `routes/tasks.js` - Update API endpoints
  - `controllers/taskController.js` - Add priority handling
- **New Components:** 
  - `migrations/add_task_priority.sql` - Database migration
- **File Size Guidelines:** All modified files stay under 300 lines
- **API Integration:** Extend existing task endpoints with priority parameter
- **Data Integration:** Add priority column to tasks table with default value

### 3. Implementation Details
**Step-by-Step Approach:**
1. Create database migration for priority field
2. Update Task model with priority enum
3. Modify task controller to handle priority in CRUD operations
4. Update API routes to accept priority parameter
5. Add validation for priority values
6. Update existing tests to include priority scenarios

**Code Examples:**
```javascript
// Task model extension (models/task.js)
const TaskPriority = {
  LOW: 'low',
  MEDIUM: 'medium', 
  HIGH: 'high'
};

// Add to existing Task schema
priority: {
  type: String,
  enum: Object.values(TaskPriority),
  default: TaskPriority.MEDIUM
}
```

**Database Migration:**
```sql
-- migrations/add_task_priority.sql
ALTER TABLE tasks 
ADD COLUMN priority VARCHAR(10) 
DEFAULT 'medium' 
CHECK (priority IN ('low', 'medium', 'high'));
```

### 4. Acceptance Criteria
- **Functional Criteria:**
  - Task model includes priority field with enum validation
  - API accepts priority in create/update operations
  - Default priority is set for existing tasks
  - Priority is returned in all task responses
  
- **Integration Criteria:**
  - Existing task functionality remains unchanged
  - All existing tests continue to pass
  - New priority field is properly validated
  
- **Performance Criteria:**
  - Database queries perform within existing benchmarks
  - API response times remain under 200ms

### 5. Testing Requirements
- **Unit Tests:**
  - Task model validates priority values correctly
  - Task model rejects invalid priority values
  - Task controller handles priority in CRUD operations
  - Default priority is applied correctly
  
- **Integration Tests:**
  - Task API accepts priority in requests
  - Task API returns priority in responses
  - Database migration applies successfully
  
- **Manual Testing:**
  - Create task with each priority level
  - Update task priority
  - Verify existing tasks have default priority

### 6. Definition of Done
- [ ] Task model includes priority field with validation
- [ ] Database migration creates priority column
- [ ] API endpoints handle priority parameter
- [ ] All tests pass including new priority tests
- [ ] Existing functionality remains unaffected
- [ ] Code follows existing style and patterns
- [ ] Git workflow completed with detailed commit
- [ ] 🧩 Memory actions completed

### 7. Dependencies and Integration
- **Required Tasks:** None (foundational task)
- **Existing Component Dependencies:** Task model, Task API, Database
- **External Dependencies:** Database migration tool
- **Integration Sequence:** This task enables all subsequent priority-related tasks
```

## Memory Actions During Process

### Initial Context Retrieval
```
memory_search "feature-brief technical-approach [feature-name]" repository="[project-repo]"
memory_store_chunk
  content="Starting implementation plan for [feature-name]. Context: [brief and approach summary]"
  tags=["implementation-plan", "started", "feature-name"]
  session_id="[current-session]"
  repository="[project-repo]"
```

### After Task Generation
```
memory_store_decision
  decision="Task breakdown for [feature-name]"
  rationale="Integration approach: [approach]. Task boundaries: [reasoning]. Implementation sequence: [sequence logic]"
  context="Total tasks: [count]. Critical path: [tasks]. Parallel opportunities: [tasks]"
  session_id="[current-session]"
  repository="[project-repo]"
```

### After Plan Completion
```
memory_create_thread
  name="Feature Implementation: [feature-name]"
  description="Complete feature development from brief through implementation tasks"
  chunk_ids=["[feature-brief-chunks]", "[tech-approach-chunks]", "[implementation-plan-chunks]"]
  repository="[project-repo]"
```

## Quality Validation

Before finalizing implementation plan, ensure:

### Task Atomicity
- [ ] **Each task is completable in 2-4 hours**
- [ ] **Clear deliverable for each task**
- [ ] **Tasks are independent where possible**
- [ ] **Dependencies are minimal and clear**

### Integration Quality
- [ ] **All integration points identified**
- [ ] **Existing system impact minimized**
- [ ] **File size limits respected**
- [ ] **Performance impact considered**

### Implementation Readiness
- [ ] **Clear implementation path for each task**
- [ ] **All dependencies available**
- [ ] **Testing approach defined**
- [ ] **Git workflow included**

## Final Instructions

1. **Integration First** - Always prioritize clean integration with existing system
2. **Atomic Focus** - Ensure tasks are truly atomic and implementable
3. **Memory Integration** - Store all decisions and patterns for future features
4. **Quality Consistency** - Maintain existing code quality and patterns
5. **Git Discipline** - Include complete git workflow for every task
6. **Performance Aware** - Consider impact on existing system performance

This implementation plan provides the final level of detail needed for efficient feature development with seamless integration into existing systems.